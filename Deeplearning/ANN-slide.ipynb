{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkblue'>Artificial Neural Network (ANN)</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Lý thuyết</font>\n",
    "Ở những chương đầu tiên trong lớp học này, chúng ta đã bắt đầu cuộc hành trình và đi qua các thuật toán học máy với neural thần kinh nhân tạo trong **chương 2, Training Simple Machine Learning Algorithms for Classification**. Neural thần kinh nhân tạo có thể được hình dung như các khối gạch được sử dụng để xây nên một mạng thần kinh nhân tạo đa lớp (Multi layers artificial NNs), cái mà chúng ta sẽ cùng đề cập tới trong chương này. \n",
    "\n",
    "### <font color='blue'>Mô hình hóa các bài toán phức tạp với ANN</font>\n",
    "Khái niệm cơ bản đằng sau các NN nhân tạo được xây dựng trên **các giả thuyết và mô hình về cách thức hoạt động của bộ não con người** để giải quyết các nhiệm vụ phức tạp. Mặc dù NN nhân tạo chỉ mới phổ biến trong những năm gần đây, nhưng những nền tảng khái niệm đầu tiên của NN được xây dựng vào những năm đầu 1940 khi Warren McCulloch và Walter Pitts lần đầu tiên mô tả lại cách mà các neural hoạt động. *{A logical calculus of the ideas immanent in nervous activity, W. S. McCulloch and W. Pitts. The Bulletin of Mathematical Biophysics, 5(4):115–133, 1943.}*\n",
    "\n",
    "Tuy nhiên, sau nhiều thập kỷ kể từ khi thực nghiệm mô hình neural nhân tạo đầu tiên được thực hiện *(Rosenblatt's perceptron vào năm 1950s)*. Nhiều nhà nghiên cứu và nghiên cứu sinh dần dần chán nản và mất đi hứng thú với NN vì không một ai vào lúc bấy giờ có thể cho ra một giải pháp tốt cho NN nhiều lớp. \n",
    "\n",
    "*Dành cho các đọc giả quan tâm đến lịch sử của Artificial Intelligence (AI), machine learning hay NN nói riêng, tôi khuyến khích các bạn đọc qua bài viết bằng tiếng Anh rất chi tiết về các giai đoạn này trên Wikipedia có tựa [AI winters](https://en.wikipedia.org/wiki/AI_winter).*\n",
    "\n",
    "Cuối cùng, vào năm 1986 khi D.E.Rumelhart, G.E. Hinton và R.J. Williams đã công bố thuật toán backpropagation để đào tạo NN hiệu quả hơn, chúng ta sẽ thảo luận chi tiết hơn sau trong chương này, đã đưa NN trở lại cuộc đua trong lĩnh vực trí nghiên cứu về trí tuệ nhân tạo cùng với sự phát triển vượt bậc của phần cứng (GPU, TPU) mà NN đã và đang ngày càng trở nên phổ biến hơn bao giờ hết. Từ đó dẫn đến sự ra đời của khái niệm kiến trúc hay giải thuật **deep learning** mà chúng ta vẫn thường hay ghe tới. Một chủ đề nóng không chỉ trong giới nghiên cứu học thuật mà còn được đầu tư một khoản không nhỏ từ các ông lớn trong ngành công nghệ như Facebook, Microsoft, Amazon, Uber, và Google.\n",
    "\n",
    "Cho đến ngày nay, các NN phức tạp được hỗ trợ bởi các thuật toán học sâu được coi là giải pháp tiên tiến (SOTA) để giải quyết vấn đề phức tạp như nhận dạng hình ảnh, giọng nói hay xử lý ngôn ngữ. Các ví dụ phổ biến về các sản phẩm trong cuộc sống hàng ngày của chúng ta được hỗ trợ bởi các NN học sâu là tìm kiếm hình ảnh của Google và Google Dịch - một ứng dụng cho điện thoại thông minh có thể tự động nhận dạng văn bản trong hình ảnh để dịch theo thời gian thực sang hơn 20 ngôn ngữ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Nhắc lại về mạng neural một lớp</font>\n",
    "Trước khi đi chi tiết hơn về kiên trúc NN đa lớp, hãy cùng nhặc lại một vài khái niệm về NN một lớp mà chúng ta đã được giới thiệu trong chương 2, Training Simple Machine Learning Algorithms for\n",
    "Classification, có tên gọi là giải thuật **ADAptive LInear NEuron (Adaline)**.\n",
    "![hinh 1](https://raw.githubusercontent.com/HuangRihChang/machine_learning_basic/master/Deeplearning/images/ANN/SLNN.png)\n",
    "<div align=\"center\">hình 1. kiến trúc của mạng neural nhân tạo một lớp</div>  \n",
    "\n",
    "Trong chương 2, chúng ta đã khai triển thuật toán Adaline để thực hiện tác vụ phân lớp nhị phân, và sử dụng thuật toán gradient descent optimization để cập nhật các hệ số trọng số của mô hình trong qua training set. Trong mỗi epoch, chúng ta cập nhật vector trọng số $w$ bằng cách sử dụng quy tắc cập nhật sau: \n",
    "$$\n",
    "\\begin{aligned}\n",
    " w:&=w+\\Delta{w}, \\text{    where $\\Delta{w} = -\\eta\\nabla{J(w)}$}\n",
    "\\end{aligned}\n",
    "$$\n",
    "nói cách khác, chúng ta đã thực hiện tính toán gradient dựa trên toàn bộ dữ liệu trong training set và cập nhật trọng số của mô hình bằng cách bước một bước về hướng ngược lại so với gradient (có thể hiểu là độ dốc) của $\\nabla{J(w)}$. Để tối ưu trọng số của mô hình, chúng ta tối ưu một objective function được xác định trước, ở đây chúng ta đã dùng Sum of Squared errors (SSE) để làm cost function $J(w)$. Tiếp đến, chúng ta còn định nghĩa learning rate dùng để cân bằng tốc độ học tập và tránh nguy cơ vượt qua Global Minimum của cost function.\n",
    "\n",
    "Trong gradient descent optimization, chúng ta cập nhật đồng thời tất cả các trọng số sau mỗi epoch, và chúng ta cũng xác định đạo hàm riêng của mỗi trọng số $w_j$ với công thức sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    " \\frac{\\partial}{\\partial{w_j}}J(w)&=-\\sum_i(y^{(i)}-a^{(i)})x^{(i)}_j\n",
    "\\end{aligned}\n",
    "$$\n",
    "Trong đó, $y^{(i)}$ là nhãn của lớp mục tiêu của mẫu $x^{(i)}$, và $a^{(i)}$ là hàm kích hoạt của neural.\n",
    "\n",
    "Xa hơn nữa, chúng ta đã định nghĩa hàm activation $\\phi(.)$ như sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    " \\phi(z) = z = a\n",
    "\\end{aligned}\n",
    "$$\n",
    "Trong đó, input $z$ là một tổ hợp tuyến tính (linear combination) có trọng số trên các cạnh nối giữa input layer và output layer:\n",
    "$$\n",
    "\\begin{aligned}\n",
    " z = \\sum_j w_j x_j = W^TX\n",
    "\\end{aligned}\n",
    "$$\n",
    "Trong khi chúng ta sử dụng activation $\\phi(z)$ để thực hiện tính toán cập nhật gradient, chúng ta còn xác định threshold để chuyển kết quả đầu ra từ giá trị trong miền liên tục qua thành giá trị nhị phân cho bài toán phân lớp nhị phân:\n",
    "$$\n",
    "\\begin{aligned}\n",
    " y = \\begin{cases}\n",
    "        1 \\: \\text{if $g(z)\\geq 0$}\\\\\n",
    "        -1 \\: \\text{otherwise}\n",
    "     \\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Đồng thời, chúng ta cũng đã được học về một mẹo để tăng tốc quá trình học tập của mô hình, được gọi **stochastic gradient descent (SGD)** optimization. SGD xấp xỉ chi phí từ một mẫu huấn luyện (online learning) hoặc từ một tập hợp nhỏ (subset) được lấy từ mẫu huấn luyện (mini-batch learning). Ngoài việc giúp mô hình học tập nhanh hơn, do việc cập nhật weights thường xuyên hơn so với GD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Giới thiệu kiến trúc mạng neural đa lớp</font>\n",
    "Trong phần này, chúng ta sẽ tìm hiểu cách kết nối nhiều neual đơn lẻ với một NN đa lớp; loại mạng đặc biệt này được gọi là Multi-Layer Perceptron (MLP). Hình dưới đây minh họa concept của một MLP gồm có ba lớp:\n",
    "![](https://raw.githubusercontent.com/HuangRihChang/machine_learning_basic/master/Deeplearning/images/ANN/FF.png)\n",
    "<div align=\"center\">hình 2. kiến trúc của mạng neural nhân tạo đa lớp</div>  \n",
    "\n",
    "MLP được mô tả ở hình trên bao gồm có một lớp đầu vào (Input layer), một lớp ẩn (hidden layer) và một lớp đầu ra (output layer). Các units ở hidden layer đều liên kết đầy đủ (fully connected) với input layer, tương tự với output layer cũng được fully connected với hidden layer trước đó. Nếu như một mạng như vậy có hơn 1 hidden layer, chúng ta gọi đó **deep artificial NN**.\n",
    "\n",
    "Như được thể hiện ở hình trước, chúng ta biểu diễn activation thứ $i$ ở lớp thứ $l$ bằng ký hiệu $a^{(l)}_i$. Để khiến cho việc triển khai toán học và coding thực nghiệm dễ dàng hơn, chúng ta sẽ không sử dụng các chỉ số bằng số để chỉ đến các lớp hay vị trí của các unit trong lớp. Thay vào đó chúng ta định nghĩa các superscript như *in* để chỉ input layer, *h* cho hidden layers, *out* cho output layer. Chú ý, để dễ dàng hơn cho việc định coding chúng ta chú ý các activation unit $a^{(in)}_0$ và $a^{(h)}_0$ là các bias units, được cài đặt mặc định bằng 1:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f&=  \\begin{bmatrix}\n",
    "        a^{(in)}_0\\\\\n",
    "        a^{(in)}_1\\\\\n",
    "        \\vdots\\\\\n",
    "        a^{(in)}_m \n",
    "    \\end{bmatrix} &= \\begin{bmatrix}\n",
    "        1\\\\\n",
    "        x^{(in)}_1\\\\\n",
    "        \\vdots\\\\\n",
    "        x^{(in)}_m \n",
    "    \\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Mỗi unit ở layer $l$ được liên kết với tất cả units ở layer $l+1$ bởi một bộ trọng số. Ví dụ, liên kết giữa unit thứ $k$ ở lớp $l$ và unit thứ $j$ ở lớp $l+1$, được ký hiệu bằng $w^{(l)}_{k,j}$. Tham khảo lại hình trước, chúng ta ký hiệu ma trận trọng số liên kết giữa input layer và hidden layer bằng $W^{(h)}$, và ma trận trọng số liên kết giữa hidden layer và output layer là $W^{(out)}$.\n",
    "\n",
    "Nhìn lại ở mô hình nhân tạo 1 lớp chúng ta thấy, trong khi với 1 unit ở output layer sẽ phù hợp với bài toán phân lớp nhị phân. Ở hình 2 chúng ta được cho thấy một dạng NN tổng quát hơn, cho phép chúng ta thực hiện phân loại đa lớp thông qua việc khái quát hóa kỹ thuật One-vs-All (OvA). Để hiểu rõ hơn về cách hoạt động của nó, chúng ta hãy cùng nhớ về cách biểu diễn one-hot đã được giới thiệu trong Chương 4, Building Good Training Datasets-Data Preprocessing.\n",
    "Ví dụ như chúng ta có 3 nhãn có được định nghĩa $[0,1,2]$, thông qua one-hot encode chúng ta sẽ có được biểu diễn sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0&=  \\begin{bmatrix}\n",
    "        1\\\\\n",
    "        0\\\\\n",
    "        0 \n",
    "    \\end{bmatrix}, 1 =\\begin{bmatrix}\n",
    "        0\\\\\n",
    "        1\\\\\n",
    "        0 \n",
    "    \\end{bmatrix}, 2 =\\begin{bmatrix}\n",
    "        0\\\\\n",
    "        0\\\\\n",
    "        1\n",
    "    \\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "OKay, vậy là với NN đa lớp và với one-hot encoding chúng ta có thể định nghĩa được bài toán phân loại đa lớp với giả định là mỗi một điểm dữ liệu cụ thể chỉ thuộc một lớp duy nhất.\n",
    "\n",
    "Bây giờ chúng ta hay tóm tắt lại các khái niệm mà đã được quy ước trong phần này với biểu diễn trực quan hóa của 3-4-3 MLP nhé:\n",
    "\n",
    "![hinh 3](https://raw.githubusercontent.com/HuangRihChang/machine_learning_basic/master/Deeplearning/images/ANN/FF2.png)\n",
    "<div align=\"center\">hình 3. Minh họa quy ước trong NN đa lớp</div>\n",
    "\n",
    "Sau khi đã biết được các khái niệm cơ bản về MLP, chúng ta cùng tìm hiểu được làm thế nào một MLP có thể học được, tương tự như ở mạng neural 1 lớp, chúng ta tóm tắt với 3 bước sau:\n",
    "- bắt đầu ở input layer, chúng ta thực hiện lan truyền tiến (feed forward hay còn có tài liệu gọi là forward propagation) những patterns của training data trên kiến trúc MLP hiện thời để tính ra được output.\n",
    "- dựa trên output của network, chúng ta thực hiện tính toán độ lỗi (error) cần cực tiểu hóa thông qua cost function (có tài liệu sẽ gọi là lost function).\n",
    "- Thực hiện quá trình lan truyền ngược (backpropagation) độ lỗi, dựa trên đó tìm đạo hàm riêng của từng trọng số trong network, và cập nhật mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Kích hoạt một NN thông qua lan truyền tiến (feed forward)</font>\n",
    "Trong phần này chúng ta sẽ cùng tìm hiểu về quá trình của quá trình feed forward để tính toán output của một mô hình MLP. \n",
    "\n",
    "Bây giờ chúng ta hãy cùng đi qua từng bước một để hiểu hơn về quá trình feed forward để tính được output. Vì mỗi unit trong hidden layer luôn được fully connected với tất cả các units ở lớp trước đó nên chúng ta tính kết quả của activation unit $a^{(h)}_1$ như sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z^{(h)}_1 &= a^{(in)}_0 w^{(h)}_{0,1} + a^{(in)}_1 w^{(h)}_{1,1}+...+a^{(in)}_m w^{(h)}_{m,1} \\\\\n",
    "a^{(h)}_1 &= \\phi(z^{(h)}_1)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Trong đó, $z^{(h)}_1$ là input của unit và $\\phi(.)$ là một activation function. Để có thể xử lý được các tác vụ phức tạp như là phân loại ảnh, hay xử lý giọng nói. Chúng ta sử dụng các hàm phi tuyến tính để làm các activation functions. Ví dụ như là hàm sigmoid đã được ví dụ ở Chương 3, A Tour of Machine Learning Classifiers Using scikit-learn:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\phi(z) = \\frac{1}{1+e^{-z}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Nhằm mục đích thuận tiện và hiệu quả trong việc code và dễ đọc, chúng ta sẽ viết lại hàm kích hoạt trên ở dạng ngắn gọn hơn bằng việc tận dụng các khái niệm trong đại số tuyến tính, cho phép chúng ta vetor hóa thông qua việc lập trình bằng numpy, thay vì viết hàng chục, hàng tỉ phép tính với python loops:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{z}^{(h)} &= \\boldsymbol{a}^{(in)}W^{(h)}\\\\\n",
    "\\boldsymbol{a}^{(h)} &= \\phi(\\boldsymbol{z}^{(h)})\n",
    "\\end{aligned}\n",
    "$$\n",
    "trong đó, $\\boldsymbol{a}^{(in)}$ là một ma trận đặc trưng của training sample có $1 \\,\\text{x}\\,m$ chiều. $W^{(h)}$ là một ma trận trọng số có $m \\, \\text{x} \\,d$ chiều. Với $m$ là số chiều đặc trưng input, $d$ là số units ở hidden layer. Sau khi thực hiện phép nhân ma trận, chúng ta thu được ma trận có $1\\,\\text{x}\\,d$ chiều dùng để làm giá trị đầu vào ròng (net input) để tính activation $\\boldsymbol{a}^{(h)}$ ($\\boldsymbol{a}^{(h)}\\in /R^{1\\,\\text{x}\\,d}$).\n",
    "\n",
    "Xa hơn nữa, chúng ta sẽ tổng quát hóa toàn bộ $n$ samples trong tập training set:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{Z}^{(h)} &= \\boldsymbol{A}^{(in)}W^{(h)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Trong đó, $\\boldsymbol{A}^{(in)}$ là một ma trận $n \\text{x} m$ chiều, sau khi thực hiện phép nhân ma trận với ma trận như trên ta thu được một ma trận $\\boldsymbol{Z}^{(h)}$ có $n\\,\\text{x}\\,d$ chiều. Cuối cùng, chúng ta áp dụng activation function $\\phi(.)$ cho ma trận giá trị đầu vào ròng vừa thu được ở bước trên để tạo ra một ma trận activation mới cùng số chiều với ma trận đầu vào ròng:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{A}^{(h)} &= \\phi(\\boldsymbol{Z}^{(h)})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Tương tự với output layer,ta có công thức sau cho output layer dưới dạng ma trận hóa:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{Z}^{(out)} &= \\boldsymbol{A}^{(h)}W^{(out)}\\\\\n",
    "\\boldsymbol{A}^{(out)} &= \\phi(\\boldsymbol{Z}^{(out)}), \\,\\,A^{(out)}\\in\\mathbb{R}^{n\\,\\text{x}\\,t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Với $t$ là số output units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Đôi chút về lan truyền ngược (backpropagation)</font>\n",
    "Mặc dù đã được (tái) khám phá và công bố hơn 30 năm qua *(Learning representations by back-propagating errors, D. E. Rumelhart, G. E. Hinton, and R. J. Williams, Nature, 323: 6088, pages 533–536, 1986)* nhưng cho đến nay, Backpropagation vẫn là một giải thuật được sử dụng chủ yếu và rộng rãi trong việc huấn luyện mạng trí tuệ nhân tạo hiệu quả nhất. \n",
    "\n",
    "Trong phần này chúng ta sẽ cùng nhắc lại một cách ngắn gọn và dễ hiểu về giải thuật này. Về bản chất, chúng ta có thể hiểu backpropagation như một cách tính toán hiệu quả cho việc tìm đạo hàm riêng của Loss Function phức tạp trong NN đa lớp. Ở đây, mục tiêu của chúng ta là sử dụng các đạo hàm riêng đó để học (cập nhật) các trọng số trong mô hình NN. Thách thức trong việc tham số hóa NN là chúng ta thường xử lý một số lượng lớn các hệ số có số chiều rất lớn. Khác với các Loss Function mà ta từng thấy ở NN 1 lớp như Adaline hay Logistic Regression, mặt lỗi (error surface) của NN đa lớp phần lớn đều không lồi, trơn và có rất nhiều các cực tiểu (local minimum) cần phải vượt qua để tìm ra giá trị nhỏ nhất (global minimum) của Loss Function.\n",
    "\n",
    "Đầu tiên, chúng ta sẽ cùng nhắc lại đôi chút về Quy tắc dây chuyền (Chain Rule) trong giải tích. Chain rule là hướng tiếp cận để giải quyết bài toán tìm đạo hàm riêng (Partial derivative) của một hàm phức tạp (complex function), hàm lồng nhau (nested function), ví dụ như sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial{x}}[h(f(x))] = \\frac{\\partial{h}}{\\partial{f}} \\cdot \\frac{\\partial f}{\\partial x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Tương tự vậy, chúng ta có thể áp dụng chain rule cho những hàm phức tạp hơn. Ví dụ như sau:\n",
    "\n",
    "Giả sử ta có 5 hàm khác nhau: $f(.),g(.),h(.),u(.)\\,\\text{ và }\\,v(x)$. Gọi $F$ là hàm hợp của 5 hàm trên: $F(x) = f(g(h(u(v(x)))))$. Áp dụng chain rule để tìm đạo hàm riêng của $x$ với $F$ ta được phương trình sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial F}{\\partial x} = \\frac{\\partial}{\\partial x}f(g(h(u(v(x))))) &= \\frac{\\partial f}{\\partial g} \\cdot \\frac{\\partial g}{\\partial h} \\cdot \\frac{\\partial h}{\\partial u} \\cdot \\frac{\\partial u}{\\partial v} \\cdot \\frac{\\partial v}{\\partial x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "***Đọc thêm:***\n",
    "\n",
    "*Đạo hàm riêng tự động (Automatic differentiation)*: [**A. G. Baydin and B. A. Pearlmutter's article Automatic Differentiation of Algorithms for Machine Learning**, *arXiv preprint arXiv:1404.7456, 2014.*](http://arxiv.org/pdf/1404.7456.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Huấn luyện NNs thông qua backpropagation</font>\n",
    "Trong phần này, chúng ta sẽ cùng nói một chút toán học về backpropagation để hiểu hơn về các mà NNs học (cập nhật) được các trọng số (weights) trong mô hình. \n",
    "\n",
    "Trước tiên, để tính được Loss và áp dụng backpropagation, chúng ta cần đi qua bước feed forward tuần tự các lớp để thu được đầu ra tại output, được mô hình hóa toán học qua như sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{Z}^{(h)} &= \\boldsymbol{A}^{(in)}W^{(h)}\\,\\,\\text{(net input of the hidden layer) (1)}\\\\\n",
    "\\boldsymbol{A}^{(h)} &= \\phi(\\boldsymbol{Z}^{(h)}) \\,\\,\\text{(activation of the hidden layer) (2)}\\\\\n",
    "\\boldsymbol{Z}^{(out)} &= \\boldsymbol{A}^{(h)}W^{(out)}\\,\\,\\text{(net input of the output layer) (3)}\\\\\n",
    "\\boldsymbol{A}^{(out)} &= \\phi(\\boldsymbol{Z}^{(out)}) \\,\\,\\text{(activation of the output layer) (4)}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Hình ảnh được mô tả với hình dưới đây:\n",
    "![](https://raw.githubusercontent.com/HuangRihChang/machine_learning_basic/master/Deeplearning/images/ANN/FF3.png)\n",
    "Trong quá trình backpropagation, chúng ta sẽ thực hiện lan truyền ngược độ lỗi (error) từ phải sáng trái (output layer - inputlayer). \n",
    "Dựa trên chain rule, ta có:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J(\\boldsymbol{W})}{\\partial{\\boldsymbol{W}^{(h)}}} &= \\frac{\\partial \\boldsymbol{Z}^{(h)}}{\\partial \\boldsymbol{W}^{(h)}} \\frac{\\partial \\boldsymbol{A}^{(h)}}{\\partial \\boldsymbol{Z}^{(h)}} \\frac{\\partial J(\\boldsymbol{W})}{\\partial \\boldsymbol{A}^{(h)}}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Dựa trên các phương trình (1) chúng ra suy ra:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\boldsymbol{Z}^{(h)}}{\\partial \\boldsymbol{W}^{(h)}} = \\boldsymbol{A}^{(in)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Đặt $\\frac{\\partial \\boldsymbol{A}^{(h)}}{\\partial \\boldsymbol{Z}^{(h)}} \\frac{\\partial J(\\boldsymbol{W})}{\\partial \\boldsymbol{A}^{(h)}} = \\delta^{(h)}$, Tiếp tục triển khai:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta^{(h)} = \\frac{\\partial \\boldsymbol{A}^{(h)}}{\\partial \\boldsymbol{Z}^{(h)}} \\frac{\\partial J(\\boldsymbol{W})}{\\partial \\boldsymbol{A}^{(h)}} =  \\frac{\\partial \\boldsymbol{A}^{(h)}}{\\partial \\boldsymbol{Z}^{(h)}} \\frac{\\partial \\boldsymbol{Z}^{(out)}}{\\partial \\boldsymbol{A}^{(h)}} \\frac{\\partial J(\\boldsymbol{W})}{\\partial \\boldsymbol{Z}^{(out)}} \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Chúng ta công thức sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta^{(h)} &= \\delta^{(out)}(\\boldsymbol{W}^{(out)})^T\\odot \\frac{\\partial \\phi{z^{(h)}}}{\\partial{z^{(h)}}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Với, $\\frac{\\partial \\phi{(z^{(h)})}}{\\partial{z^{(h)}}}$ là đạo hàm của activation function, cái chúng ta sẽ cùng tính một vài hàm activation cơ bản ở phần sau. Ở đây, để cho đơn giản, chúng ta giả sử activation function sẽ sử dụng là hàm sigmoid, có đạo hàm như sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial\\phi{(z)}}{\\partial{z}} = \\phi'(z) =(\\phi{(z)}\\odot(1-\\phi{(z)}))\n",
    "\\end{aligned}\n",
    "$$\n",
    "và  $\\delta^{(out)}$ ta tính bằng phương pháp (chứng minh ở [link]( https://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function) này):\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta^{(out)} = a^{(out)} - y\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Trong đó, $y$ là ma trận giá trị nhãn (true class labels). \n",
    "\n",
    "\n",
    "Phép $\\odot$ được đề cập đến ở 2 công thức trên là phép nhân nguyên tố (element-wise multiplication).\n",
    "\n",
    "$\\delta^{(h)}$ sẽ thu được công thức sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta^{(h)} &= \\delta^{(out)}(\\boldsymbol{W}^{(out)})^T\\odot(a^{(h)}\\odot(1-a^{(h)}))\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Chúng ta có thể hình dung phép tính trên như sau: $(n \\text{,} h) = (n \\text{,} c)\\cdot(c \\text{,} h) \\odot (n \\text{,} h)$ với $n$ là số dữ liệu traning, $c$ là số classes, $h$ là số hidden activation units.\n",
    "\n",
    "Để dễ dàng thực nghiệm và lập trình, chúng ta vector hóa công thức dưới dạng sau:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Delta^{(h)} = (\\boldsymbol{A}^{(in)})^T \\delta^{(h)}\\\\\n",
    "\\Delta^{(out)} = (\\boldsymbol{A}^{(h)})^{T} \\delta^{(out)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Cuối cùng, sau khi đã tính được gradients, chúng ta có thể cập nhật trọng số của mô hình ở mỗi lớp $l$ bằng cách đi ngược chiều của một step của gradient:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{W}^{(l)}:=\\boldsymbol{W}^{(l)}-\\eta\\Delta^{(l)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "![](https://raw.githubusercontent.com/HuangRihChang/machine_learning_basic/master/Deeplearning/images/ANN/BF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Các activation function thường gặp\n",
    "\n",
    "**Sigmoid**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma(s) = \\frac{1}{1+e^{-s}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**swish**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{swish}(s) = s*\\sigma(s) = \\frac{s}{1+e^{-s}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**tanh**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{tanh}(s) = 2\\sigma(2s)-1 = \\frac{e^s-e^{-s}}{e^s+e^{-s}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**relu**\n",
    "$$\n",
    "\\begin{aligned}\n",
    " \\text{relu}(s) = \\text{max}(0,s)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Note**: Các hàm trên được áp dụng cho một số thực $(s \\in \\mathbb{R})$, khi áp dụng đầu vào là một vector thì các hàm trên được áp dụng trên từng phần tử (element-wise).\n",
    "\n",
    "------------------------------------\n",
    "**softmax**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma (\\mathbf {z} )_{i}={\\frac {e^{\\beta z_{i}}}{\\sum _{j=1}^{K}e^{\\beta z_{j}}}}{\\text{ với }}i=1,\\dotsc ,K\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175.188px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}