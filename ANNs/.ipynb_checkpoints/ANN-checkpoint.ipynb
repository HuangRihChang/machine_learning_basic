{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkblue'>Artificial Neural Network (ANN)</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Lý thuyết</font>\n",
    "Ở những chương đầu tiên trong lớp học này, chúng ta đã bắt đầu cuộc hành trình và đi qua các thuật toán học máy với neural thần kinh nhân tạo trong **chương 2, Training Simple Machine Learning Algorithms for Classification**. Neural thần kinh nhân tạo có thể được hình dung như các khối gạch được sử dụng để xây nên một mạng thần kinh nhân tạo đa lớp (Multi layers artificial NNs), cái mà chúng ta sẽ cùng đề cập tới trong chương này. \n",
    "\n",
    "### <font color='blue'>Mô hình hóa các bài toán phức tạp với ANN</font>\n",
    "Khái niệm cơ bản đằng sau các NN nhân tạo được xây dựng trên **các giả thuyết và mô hình về cách thức hoạt động của bộ não con người** để giải quyết các nhiệm vụ phức tạp. Mặc dù NN nhân tạo chỉ mới phổ biến trong những năm gần đây, nhưng những nền tảng khái niệm đầu tiên của NN được xây dựng vào những năm đầu 1940 khi Warren McCulloch và Walter Pitts lần đầu tiên mô tả lại cách mà các neural hoạt động. *{A logical calculus of the ideas immanent in nervous activity, W. S. McCulloch and W. Pitts. The Bulletin of Mathematical Biophysics, 5(4):115–133, 1943.}*\n",
    "\n",
    "Tuy nhiên, sau nhiều thập kỷ kể từ khi thực nghiệm mô hình neural nhân tạo đầu tiên được thực hiện *(Rosenblatt's perceptron vào năm 1950s)*. Nhiều nhà nghiên cứu và nghiên cứu sinh dần dần chán nản và mất đi hứng thú với NN vì không một ai vào lúc bấy giờ có thể cho ra một giải pháp tốt cho NN nhiều lớp. \n",
    "\n",
    "*Dành cho các đọc giả quan tâm đến lịch sử của Artificial Intelligence (AI), machine learning hay NN nói riêng, tôi khuyến khích các bạn đọc qua bài viết bằng tiếng Anh rất chi tiết về các giai đoạn này trên Wikipedia có tựa [AI winters](https://en.wikipedia.org/wiki/AI_winter).*\n",
    "\n",
    "Cuối cùng, vào năm 1986 khi D.E.Rumelhart, G.E. Hinton và R.J. Williams đã công bố thuật toán backpropagation để đào tạo NN hiệu quả hơn, chúng ta sẽ thảo luận chi tiết hơn sau trong chương này, đã đưa NN trở lại cuộc đua trong lĩnh vực trí nghiên cứu về trí tuệ nhân tạo cùng với sự phát triển vượt bậc của phần cứng (GPU, TPU) mà NN đã và đang ngày càng trở nên phổ biến hơn bao giờ hết. Từ đó dẫn đến sự ra đời của khái niệm kiến trúc hay giải thuật **deep learning** mà chúng ta vẫn thường hay ghe tới. Một chủ đề nóng không chỉ trong giới nghiên cứu học thuật mà còn được đầu tư một khoản không nhỏ từ các ông lớn trong ngành công nghệ như Facebook, Microsoft, Amazon, Uber, và Google.\n",
    "\n",
    "Cho đến ngày nay, các NN phức tạp được hỗ trợ bởi các thuật toán học sâu được coi là giải pháp tiên tiến (SOTA) để giải quyết vấn đề phức tạp như nhận dạng hình ảnh, giọng nói hay xử lý ngôn ngữ. Các ví dụ phổ biến về các sản phẩm trong cuộc sống hàng ngày của chúng ta được hỗ trợ bởi các NN học sâu là tìm kiếm hình ảnh của Google và Google Dịch - một ứng dụng cho điện thoại thông minh có thể tự động nhận dạng văn bản trong hình ảnh để dịch theo thời gian thực sang hơn 20 ngôn ngữ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Nhắc lại về mạng lưới thần kinh một lớp</font>\n",
    "![./SLNN.png](attachment:https://drive.google.com/file/d/1nLlf2-vycDEU0PLkBTvfXW59wxa5eFcA/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkblue'>Thực hành:\n",
    "Trong bài này, bạn sẽ thực hành: \n",
    "- (i) tiền xử lý dữ liệu\n",
    "- (ii) huấn luyện Neural Net với weight decay và early stopping.\n",
    "\n",
    "Bộ dữ liệu được sử dụng là bộ [Kaggle Titanic](https://www.kaggle.com/c/titanic); trong đó, đầu vào là thông tin của hành khách trên tàu Titanic (bạn xem chi tiết trong file `description.txt` đính kèm), đầu ra là một trong hai lớp sống/chết (1 | 0). Mình có đính kèm các file dữ liệu: `train.csv` - tập huấn luyện, `val.csv` - tập validation, `test.csv` - tập kiểm tra (chỉ có đầu vào); thật ra, Kaggle chỉ cung cấp hai file là `train.csv` và `test.csv`, mình đã tách file `train.csv` của Kaggle ra hai file là `train.csv` (80%) và `val.csv` (20%).\n",
    "\n",
    "### <font color='blue'>Import</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy, re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from tqdm.notebook import tqdm\n",
    "#import cPickle\n",
    "# You can also import other things ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Đọc dữ liệu tập huấn luyện và tập validation vào data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apellation = [' Mr',' Master',' Mrs',' Miss',' Dr',' Rev',' Don',' Col',' Jonkheer',\n",
    "              ' Ms',' Mlle',' Mme',' the Countess',' Major',' Lady',' Capt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 11 columns):\n",
      "Survived    712 non-null int64\n",
      "Pclass      712 non-null int64\n",
      "Name        712 non-null object\n",
      "Sex         712 non-null object\n",
      "Age         574 non-null float64\n",
      "SibSp       712 non-null int64\n",
      "Parch       712 non-null int64\n",
      "Ticket      712 non-null object\n",
      "Fare        712 non-null float64\n",
      "Cabin       160 non-null object\n",
      "Embarked    711 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 66.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Yousseff, Mr. Gerious</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2627</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>649</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Willey, Mr. Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O./P.P. 751</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eric</td>\n",
       "      <td>male</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Spencer, Mrs. William Augustus (Marie Eugenie)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17569</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>B78</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Touma, Mrs. Darwis (Hanne Youssef Razi)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2650</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                                            Name  \\\n",
       "PassengerId                                                                     \n",
       "496                 0       3                           Yousseff, Mr. Gerious   \n",
       "649                 0       3                              Willey, Mr. Edward   \n",
       "279                 0       3                              Rice, Master. Eric   \n",
       "32                  1       1  Spencer, Mrs. William Augustus (Marie Eugenie)   \n",
       "256                 1       3         Touma, Mrs. Darwis (Hanne Youssef Razi)   \n",
       "\n",
       "                Sex   Age  SibSp  Parch         Ticket      Fare Cabin  \\\n",
       "PassengerId                                                              \n",
       "496            male   NaN      0      0           2627   14.4583   NaN   \n",
       "649            male   NaN      0      0  S.O./P.P. 751    7.5500   NaN   \n",
       "279            male   7.0      4      1         382652   29.1250   NaN   \n",
       "32           female   NaN      1      0       PC 17569  146.5208   B78   \n",
       "256          female  29.0      0      2           2650   15.2458   NaN   \n",
       "\n",
       "            Embarked  \n",
       "PassengerId           \n",
       "496                C  \n",
       "649                S  \n",
       "279                Q  \n",
       "32                 C  \n",
       "256                C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "train_df.info()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 529 to 685\n",
      "Data columns (total 11 columns):\n",
      "Survived    179 non-null int64\n",
      "Pclass      179 non-null int64\n",
      "Name        179 non-null object\n",
      "Sex         179 non-null object\n",
      "Age         140 non-null float64\n",
      "SibSp       179 non-null int64\n",
      "Parch       179 non-null int64\n",
      "Ticket      179 non-null object\n",
      "Fare        179 non-null float64\n",
      "Cabin       44 non-null object\n",
      "Embarked    178 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 16.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Salonen, Mr. Johan Werner</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3101296</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363592</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Kimball, Mr. Edwin Nelson Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11753</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Morley, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364506</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>599</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Boulos, Mr. Hanna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2664</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                          Name   Sex   Age  \\\n",
       "PassengerId                                                               \n",
       "529                 0       3     Salonen, Mr. Johan Werner  male  39.0   \n",
       "697                 0       3              Kelly, Mr. James  male  44.0   \n",
       "622                 1       1  Kimball, Mr. Edwin Nelson Jr  male  42.0   \n",
       "462                 0       3           Morley, Mr. William  male  34.0   \n",
       "599                 0       3             Boulos, Mr. Hanna  male   NaN   \n",
       "\n",
       "             SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                 \n",
       "529              0      0  3101296   7.9250   NaN        S  \n",
       "697              0      0   363592   8.0500   NaN        S  \n",
       "622              1      0    11753  52.5542   D19        S  \n",
       "462              0      0   364506   8.0500   NaN        S  \n",
       "599              0      0     2664   7.2250   NaN        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv('val.csv', index_col=0)\n",
    "val_df.info()\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tiền xử lý tập huấn luyện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_df = train_df.iloc[:, 1:]\n",
    "train_output_df = train_df.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Xây dựng `train_X` từ `train_input_df`\n",
    "\n",
    "(`train_X` là mảng numpy chứa các véc-tơ đầu vào mà có thể đưa trực tiếp vào mô hình học như ở các bài tập trước.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, ta sẽ tiến hành: \n",
    "- Bỏ cột `Cabin` vì cột này có nhiều giá thiếu (552/712) (và có vẻ cột này sẽ không giúp ích được gì nhiều cho việc dự đoán sống/chết).\n",
    "- Bỏ cột `Ticket` vì cột này có giá trị không phải dạng số, sẽ cần phải tốn sức để chuyển sang dạng số (và có vẻ cột này cũng sẽ không giúp ích được gì nhiều cho việc dự đoán sống/chết).\n",
    "- Bỏ cột `Name` vì cột này có giá trị không phải dạng số, sẽ cần phải tốn sức để chuyển sang dạng số. Lưu ý là, việc bỏ cột `Name` có thể sẽ làm mất mát thông tin cần thiết để dự đoán sống/chết (vì trong cột `Name` có các từ như là `Miss`, `Mrs`, `Mr`, ... có thể sẽ có ích cho việc dự đoán); tuy nhiên, ở đây, để đơn giản, ta bỏ luôn :-)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 8 columns):\n",
      "Pclass      712 non-null int64\n",
      "Name        712 non-null object\n",
      "Sex         712 non-null object\n",
      "Age         574 non-null float64\n",
      "SibSp       712 non-null int64\n",
      "Parch       712 non-null int64\n",
      "Fare        712 non-null float64\n",
      "Embarked    711 non-null object\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 50.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dropped_cols = ['Ticket', 'Cabin']\n",
    "train_input_df.drop(dropped_cols, axis=1, inplace=True)\n",
    "train_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kế đến, ta sẽ xử lý các giá trị thiếu ở cột `Age` và cột `Embarked`. Ở đây, ta xử lý đơn giản là điền giá trị mean (giá trị trung bình) vào các giá trị thiếu ở cột `Age`, và điền giá trị mode (giá trị xuất hiện nhiều nhất) vào các giá trị thiếu ở cột `Embarked`. *Lưu ý là, khi điền các giá trị thiếu ở tập validation/test, ta sẽ sử dụng các giá trị mean/mode được tính từ tập huấn luyện*. Trong thực tế,  ta thường sẽ không biết ở thời điểm test biến đầu vào nào sẽ thiếu giá trị; do đó, ta có thể làm một cách tổng quát như sau: với biến đầu vào có giá trị số, ta sẽ điền giá trị mean; ngược lại, điền giá trị mode. Dưới đây, hàm `compute_mean_mode` sẽ tính từ tập huấn luyện giá trị mean/mode của *tất cả* các biến đầu vào; hàm `fill_missing_values` sẽ dùng các giá trị mean/mode này để điền giá trị thiếu cho một tập dữ liệu nào đó (tập huấn luyện/validation/kiểm tra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_Name(input_df):\n",
    "    index = input_df.index.values.tolist()\n",
    "    vector = []\n",
    "    for key in apellation:\n",
    "        tmp = list([])\n",
    "        for i in index:\n",
    "            apell = input_df.loc[i][\"Name\"].split(',')[1].split('.')[0]\n",
    "            if(apell == key):\n",
    "                tmp.append(1.0)\n",
    "            else:\n",
    "                tmp.append(0.0)\n",
    "        vector.append(tmp)\n",
    "        k = 6\n",
    "    for i in range(len(vector)):\n",
    "        input_df.insert(k+i, apellation[i], vector[i], allow_duplicates = True)\n",
    "    input_df.drop('Name', axis=1, inplace=True)\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_mode(train_input_df):\n",
    "    '''\n",
    "    Computes means for numeric input variables and modes for non-numeric ones.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_input_df : data frame\n",
    "        The data frame containing training inputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_mode_dict : dictionary, len = # input variables (# columns) of train_input_df\n",
    "        mean_mode_dict[<column_name>] = mean/mode of this column.\n",
    "    '''\n",
    "    dic = {}\n",
    "    for column in train_input_df:\n",
    "        num = 0\n",
    "        for i in range(7000):\n",
    "            try:\n",
    "                a = train_input_df.loc[i][column]\n",
    "                num = i\n",
    "                break\n",
    "            except:\n",
    "                next\n",
    "        if (isinstance(train_input_df.loc[num][column], str)):\n",
    "            if(len(train_input_df[column].mode()) > 0):\n",
    "                dic[column] = str(train_input_df[column].mode()[0])\n",
    "            else:\n",
    "                dic[column] = ''\n",
    "        else:\n",
    "            dic[column] = train_input_df[column].mean()\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pclass': 2.3230337078651684,\n",
       " 'Name': 'Abbott, Mr. Rossmore Edward',\n",
       " 'Sex': 'male',\n",
       " 'Age': 29.488815331010457,\n",
       " 'SibSp': 0.5140449438202247,\n",
       " 'Parch': 0.37359550561797755,\n",
       " 'Fare': 32.18301095505614,\n",
       " 'Embarked': 'S'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_mode_dict = compute_mean_mode(train_input_df)\n",
    "mean_mode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(input_df, mean_mode_dict):\n",
    "    '''\n",
    "    Fills missing values for ALL columns of `input_df` using `mean_mode_dict`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_df : data frame\n",
    "        The data frame containing inputs.\n",
    "    mean_mode_dict : dictionary\n",
    "        mean_mode_dict[<column_name>] = mean/mode of this column (estimated from the training set).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    filled_input_df : data frame\n",
    "        The data frame containing inputs after filling missing values.\n",
    "    '''\n",
    "    for column in input_df:\n",
    "        df = input_df[pd.isnull(input_df).any(axis=1)]\n",
    "        index = df.index.to_numpy()\n",
    "        for i in index:\n",
    "            if(pd.isnull(input_df.loc[i, column])):\n",
    "                input_df.loc[i, column] = mean_mode_dict[column]\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\n",
      "496   NaN\n",
      "649   NaN\n",
      "32    NaN\n",
      "299   NaN\n",
      "368   NaN\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "PassengerId\n",
      "62    NaN\n",
      "Name: Embarked, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Before filling\n",
    "missing_age_mask = train_input_df.Age.isnull()\n",
    "missing_embarked_mask = train_input_df.Embarked.isnull()\n",
    "print(train_input_df.Age[missing_age_mask].head())\n",
    "print()\n",
    "print(train_input_df.Embarked[missing_embarked_mask].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\n",
      "496    29.488815\n",
      "649    29.488815\n",
      "32     29.488815\n",
      "299    29.488815\n",
      "368    29.488815\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "PassengerId\n",
      "62    S\n",
      "Name: Embarked, dtype: object\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 8 columns):\n",
      "Pclass      712 non-null int64\n",
      "Name        712 non-null object\n",
      "Sex         712 non-null object\n",
      "Age         712 non-null float64\n",
      "SibSp       712 non-null int64\n",
      "Parch       712 non-null int64\n",
      "Fare        712 non-null float64\n",
      "Embarked    712 non-null object\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 70.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Fill and check the result\n",
    "train_input_df = fill_missing_values(train_input_df, mean_mode_dict)\n",
    "print(train_input_df.Age[missing_age_mask].head())\n",
    "print()\n",
    "print(train_input_df.Embarked[missing_embarked_mask].head())\n",
    "print()\n",
    "train_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đến đây, ta đã bỏ các cột `Name`, `Ticket`, `Cabin`; và điền giá trị thiếu cho cột `Age`, `Embarked`. Kế đến, ta sẽ chuyển các cột có giá trị không phải dạng số (`Sex` và `Embarked`) sang dạng số. Vì `Sex` và `Embarked` là các biến có giá trị rời-rạc và không-có-thứ-tự nên ta có thể chuyển sang dạng \"one-hot\" (và bỏ cột cuối). Vd:\n",
    "\n",
    "```\n",
    "Sex    --> Female | Male\n",
    "------     --------------\n",
    "female --> 1      | 0\n",
    "male   --> 0      | 1\n",
    "female --> 1      | 0\n",
    "```\n",
    "và ta có thể bỏ cột `Male` đi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical_cols(input_df):\n",
    "    '''\n",
    "    Converts `Sex` column and `Embarked` column to one-hot forms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_df : data frame\n",
    "        The data frame containing inputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numeric_input_df : data frame\n",
    "        The data frame containing inputs after converting.\n",
    "    '''\n",
    "    sex_tag = ['female', 'male']\n",
    "    Embarked_tag = ['C','Q','S']\n",
    "    index = input_df.index.to_numpy()\n",
    "    value_sex = []\n",
    "    value_C = []\n",
    "    value_Q = []\n",
    "    \n",
    "    print(len(input_df))\n",
    "    \n",
    "    try:\n",
    "        for i in range(len(index)):\n",
    "            if(input_df.loc[int(index[i])]['Sex'] == sex_tag[0]):\n",
    "                value_sex.append(1.0)\n",
    "            else:\n",
    "                value_sex.append(0.0)\n",
    "            if(input_df.loc[int(index[i])]['Embarked'] == Embarked_tag[0]):\n",
    "                value_C.append(1.0)\n",
    "            else:\n",
    "                value_C.append(0.0)\n",
    "            if(input_df.loc[int(index[i])]['Embarked'] == Embarked_tag[1]):\n",
    "                value_Q.append(1.0)\n",
    "            else:\n",
    "                value_Q.append(0.0)\n",
    "    \n",
    "        input_df.insert(6, 'female', value_sex, allow_duplicates = True)\n",
    "        input_df.insert(7, 'C', value_C, allow_duplicates = True)\n",
    "        input_df.insert(8, 'Q', value_Q, allow_duplicates = True)\n",
    "        input_df.drop('Sex', axis=1, inplace=True)\n",
    "        input_df.drop('Embarked', axis=1, inplace=True)\n",
    "    except:\n",
    "        return input_df\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 9 columns):\n",
      "Pclass    712 non-null int64\n",
      "Name      712 non-null object\n",
      "Age       712 non-null float64\n",
      "SibSp     712 non-null int64\n",
      "Parch     712 non-null int64\n",
      "female    712 non-null float64\n",
      "C         712 non-null float64\n",
      "Q         712 non-null float64\n",
      "Fare      712 non-null float64\n",
      "dtypes: float64(5), int64(3), object(1)\n",
      "memory usage: 75.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_input_df = process_categorical_cols(train_input_df)\n",
    "train_input_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 24 columns):\n",
      "Pclass           712 non-null int64\n",
      "Age              712 non-null float64\n",
      "SibSp            712 non-null int64\n",
      "Parch            712 non-null int64\n",
      "female           712 non-null float64\n",
      " Mr              712 non-null float64\n",
      " Master          712 non-null float64\n",
      " Mrs             712 non-null float64\n",
      " Miss            712 non-null float64\n",
      " Dr              712 non-null float64\n",
      " Rev             712 non-null float64\n",
      " Don             712 non-null float64\n",
      " Col             712 non-null float64\n",
      " Jonkheer        712 non-null float64\n",
      " Ms              712 non-null float64\n",
      " Mlle            712 non-null float64\n",
      " Mme             712 non-null float64\n",
      " the Countess    712 non-null float64\n",
      " Major           712 non-null float64\n",
      " Lady            712 non-null float64\n",
      " Capt            712 non-null float64\n",
      "C                712 non-null float64\n",
      "Q                712 non-null float64\n",
      "Fare             712 non-null float64\n",
      "dtypes: float64(21), int64(3)\n",
      "memory usage: 159.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_input_df = preprocessing_Name(train_input_df)\n",
    "train_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, ta sẽ xây dựng `train_X`. Để giúp Gradient Descent hội tụ nhanh hơn, ta sẽ chuẩn hóa để các cột của `train_X` có mean bằng 0 và có độ lệch chuẩn bằng 1. *Lưu ý là, khi chuẩn hóa `val_X`/`test_X`, ta sẽ dùng mean và độ lệch chuẩn được ước lượng từ tập huấn luyện.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 24)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_input_df.values\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute `X_mean` and `X_std`\n",
    "X_mean = train_X.mean(axis=0)\n",
    "X_std = train_X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.32303371e+00 2.94888153e+01 5.14044944e-01 3.73595506e-01\n",
      " 3.49719101e-01 5.80056180e-01 4.63483146e-02 1.27808989e-01\n",
      " 2.12078652e-01 7.02247191e-03 8.42696629e-03 1.40449438e-03\n",
      " 2.80898876e-03 1.40449438e-03 1.40449438e-03 2.80898876e-03\n",
      " 1.40449438e-03 1.40449438e-03 2.80898876e-03 1.40449438e-03\n",
      " 1.40449438e-03 1.79775281e-01 8.42696629e-02 3.21830110e+01]\n",
      "[8.34392606e-01 1.31205457e+01 1.07438220e+00 8.00827868e-01\n",
      " 4.76881171e-01 4.93549398e-01 2.10238313e-01 3.33877000e-01\n",
      " 4.08780255e-01 8.35054298e-02 9.14108994e-02 3.74502574e-02\n",
      " 5.29254036e-02 3.74502574e-02 3.74502574e-02 5.29254036e-02\n",
      " 3.74502574e-02 3.74502574e-02 5.29254036e-02 3.74502574e-02\n",
      " 3.74502574e-02 3.84000168e-01 2.77791805e-01 5.22947658e+01]\n"
     ]
    }
   ],
   "source": [
    "print(X_mean)\n",
    "print(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train_X using X_mean and X_std\n",
    "train_X = (train_X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.09570189e-16 -4.98976640e-18  1.24744160e-18 -4.24130144e-17\n",
      "  6.48669632e-17  3.99181312e-17 -2.49488320e-18 -3.49283648e-17\n",
      "  8.60734704e-17 -9.97953281e-18 -7.48464960e-18  2.49488320e-18\n",
      " -9.97953281e-18 -2.49488320e-18  2.49488320e-18  0.00000000e+00\n",
      " -4.98976640e-18  0.00000000e+00 -9.97953281e-18  2.49488320e-18\n",
      "  2.49488320e-18  2.49488320e-17  7.48464960e-18 -5.48874304e-17]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(train_X.mean(axis=0))\n",
    "print(train_X.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 25)\n"
     ]
    }
   ],
   "source": [
    "# Add x_0 column\n",
    "train_X = np.hstack([np.ones((len(train_X), 1)), train_X])\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2. Xây dựng `train_Y` từ `train_output_df`**\n",
    "\n",
    "(`train_Y` là mảng numpy chứa các đầu ra đúng mà có thể đưa trực tiếp vào mô hình học như ở các bài tập trước.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "train_Y = train_output_df.values.reshape(-1, 1)\n",
    "enc.fit(train_Y)\n",
    "\n",
    "train_Y = enc.transform(train_Y).toarray()\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_df.to_csv('text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Tiền xử lý tập validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_input_df = val_df.iloc[:, 1:]\n",
    "val_output_df = val_df.Survived\n",
    "len(val_input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. Xây dựng `val_X` từ `val_input_df`**\n",
    "\n",
    "Cách xây dựng `test_X` từ `test_input_df` sẽ *giống hệt* cách xây dựng `val_X` từ `val_input_df`. Do đó, ta sẽ viết phần xử lý này vào một hàm để lúc sau có thể dùng lại cho tập kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_input_df(new_input_df, dropped_cols, mean_mode_dict, X_mean, X_std):\n",
    "    '''\n",
    "    Builds `new_X` from `new_input_df`:\n",
    "    1. Drop columns using `dropped_cols` (`dropped_cols` is the list containing names of dropped columns)\n",
    "    2. Fill missing values using `mean_mode_dict` (use `fill_missing_values` function)\n",
    "    3. Convert categorial columns to one-hot (use `process_categorical_cols` function)\n",
    "    4. Subtract by `X_mean` and divide by `X_std`\n",
    "    5. Add `x_0` column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    I'm lazy now ...\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_X : numpy array\n",
    "        The matrix of input vectors.\n",
    "    '''\n",
    "    # TODO\n",
    "    new_input_df = new_input_df.drop(dropped_cols, axis=1)\n",
    "    new_input_df = fill_missing_values(new_input_df, mean_mode_dict)\n",
    "    new_input_df = process_categorical_cols(new_input_df)\n",
    "    new_input_df = preprocessing_Name(new_input_df)\n",
    "    print(new_input_df.info())\n",
    "    new_X = new_input_df.values\n",
    "    new_X = (new_X - X_mean)/X_std\n",
    "    new_X = np.hstack([np.ones((len(new_X), 1)), new_X])\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 529 to 685\n",
      "Data columns (total 24 columns):\n",
      "Pclass           179 non-null int64\n",
      "Age              179 non-null float64\n",
      "SibSp            179 non-null int64\n",
      "Parch            179 non-null int64\n",
      "female           179 non-null float64\n",
      " Mr              179 non-null float64\n",
      " Master          179 non-null float64\n",
      " Mrs             179 non-null float64\n",
      " Miss            179 non-null float64\n",
      " Dr              179 non-null float64\n",
      " Rev             179 non-null float64\n",
      " Don             179 non-null float64\n",
      " Col             179 non-null float64\n",
      " Jonkheer        179 non-null float64\n",
      " Ms              179 non-null float64\n",
      " Mlle            179 non-null float64\n",
      " Mme             179 non-null float64\n",
      " the Countess    179 non-null float64\n",
      " Major           179 non-null float64\n",
      " Lady            179 non-null float64\n",
      " Capt            179 non-null float64\n",
      "C                179 non-null float64\n",
      "Q                179 non-null float64\n",
      "Fare             179 non-null float64\n",
      "dtypes: float64(21), int64(3)\n",
      "memory usage: 40.0 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179, 25)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = process_new_input_df(val_input_df, dropped_cols, mean_mode_dict, X_mean, X_std)\n",
    "val_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. Xây dựng `val_Y` từ `val_output_df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_Y = val_output_df.values.reshape(-1, 1)\n",
    "# val_Y = enc.transform(val_Y).toarray()\n",
    "val_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Các activation function thường gặp\n",
    "\n",
    "**Sigmoid**\n",
    "\n",
    "\n",
    "**tanh**\n",
    "\n",
    "\n",
    "**relu**\n",
    "\n",
    "\n",
    "**softmax**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Sigmoid activation function.\n",
    "        g(z) = 1 / (1 + e^-z)\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    \"\"\"\n",
    "    Tanh activation function.\n",
    "        g(z) = tanh(z)\n",
    "    \"\"\"\n",
    "    return np.tanh(z)\n",
    "\n",
    "def relu(z):\n",
    "    \"\"\"\n",
    "    Relu activation function.\n",
    "        g(z) = max(0, z)\n",
    "    \"\"\"\n",
    "    return z*(z > 0)\n",
    "\n",
    "def softmax(z, axis=-1):\n",
    "    \"\"\"\n",
    "    Softmax activation function. Use at the output layer.\n",
    "        g(z) = e^z / sum(e^z)\n",
    "    \"\"\"\n",
    "    z_prime = z - np.max(z, axis=axis, keepdims=True)\n",
    "    return np.exp(z_prime) / np.sum(np.exp(z_prime), axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivative của các Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(z):\n",
    "    \"\"\"\n",
    "    Sigmoid derivative.\n",
    "        g'(z) = g(z)(1-g(z))\n",
    "    \"\"\"\n",
    "    return z*(1-z)\n",
    "\n",
    "def tanh_grad(z):\n",
    "    \"\"\"\n",
    "    Tanh derivative.\n",
    "        g'(z) = 1 - g^2(z).\n",
    "    \"\"\"\n",
    "    return 1 - z**2\n",
    "\n",
    "def relu_grad(z):\n",
    "    \"\"\"\n",
    "    Relu derivative.\n",
    "        g'(z) = 0 if g(z) <= 0\n",
    "        g'(z) = 1 if g(z) > 0\n",
    "    \"\"\"\n",
    "    return 1*(z > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_normal(weight_shape):\n",
    "    \"\"\"\n",
    "    Initialize weights according `He normal` distribution. With mean = 0, std = sqrt(2 / num_input)\n",
    "    \"\"\"\n",
    "    if len(weight_shape) == 4:\n",
    "        fW, fH, fC, _ = weight_shape\n",
    "        return np.random.normal(0, np.sqrt(2 / (fW*fH*fC)), weight_shape)\n",
    "    num_input, _ = weight_shape\n",
    "    return np.random.normal(0, np.sqrt(2 / num_input), weight_shape)\n",
    "\n",
    "def he_uniform(weight_shape):\n",
    "    \"\"\"\n",
    "    Initialize weights according `He uniform` distribution within the range [-limit, limit].\n",
    "                With limit = sqrt(6 / num_input)\n",
    "    \"\"\"\n",
    "    if len(weight_shape) == 4:\n",
    "        fW, fH, fC, _ = weight_shape\n",
    "        return np.random.uniform(-np.sqrt(6 / (fW*fH*fC)), np.sqrt(6 / (fW*fH*fC)), weight_shape)\n",
    "    num_input, _ = weight_shape\n",
    "    return np.random.uniform(-np.sqrt(6 / num_input), np.sqrt(6 / num_input), weight_shape)\n",
    "\n",
    "def xavier_normal(weight_shape):\n",
    "    \"\"\"\n",
    "    Initialize weights according `Xavier normal` distribution. With mean = 0, std = sqrt(2 / (num_input + num_output))\n",
    "    \"\"\"\n",
    "    if len(weight_shape) == 4:\n",
    "        fW, fH, fC, num_fitls = weight_shape\n",
    "        return np.random.normal(0, np.sqrt(2 / (fW*fH*fC + num_fitls)), weight_shape)\n",
    "    num_input, num_output = weight_shape\n",
    "    return np.random.normal(0, np.sqrt(2 / (num_input + num_output)), weight_shape)\n",
    "\n",
    "def xavier_uniform(weight_shape):\n",
    "    \"\"\"\n",
    "    Initialize weights according `Xavier uniform` distribution within the range [-limit, limit].\n",
    "                With limit = sqrt(6 / (num_input + num_output))\n",
    "    \"\"\"\n",
    "    if len(weight_shape) == 4:\n",
    "        fW, fH, fC, num_fitls = weight_shape\n",
    "        return np.random.uniform(-np.sqrt(6 / (fW*fH*fC + num_fitls)), np.sqrt(6 / (fW*fH*fC + num_fitls)), weight_shape)\n",
    "    num_input, num_output = weight_shape\n",
    "    return np.random.uniform(-np.sqrt(6 / (num_input + num_output)), np.sqrt(6 / (num_input + num_output)), weight_shape)\n",
    "\n",
    "def standard_normal(weight_shape):\n",
    "    \"\"\"\n",
    "    Initialize weights according standard normal distribution with mean 0 variance 1.\n",
    "    \"\"\"\n",
    "    return np.random.normal(size=weight_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm huấn luyện Neural Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialization_mapping = {\"he_normal\": he_normal, \"xavier_normal\": xavier_normal, \"std\": standard_normal,\n",
    "                          \"he_uniform\": he_uniform, \"xavier_uniform\": xavier_uniform}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def forward(self, X):\n",
    "        raise NotImplementedError(\"forward() function not defined\")\n",
    "\n",
    "    def backward(self):\n",
    "        raise NotImplementedError(\"backward() function not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnableLayer:\n",
    "\n",
    "    def forward(self, X):\n",
    "        raise NotImplementedError(\"forward() function not defined\")\n",
    "\n",
    "    def backward_layer(self):\n",
    "        pass\n",
    "\n",
    "    def backward(self):\n",
    "        raise NotImplementedError(\"backward() function not defined\")\n",
    "\n",
    "    def update_params(self, grad):\n",
    "        self.W = self.W - grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Layer):\n",
    "\n",
    "    def __init__(self, return_dX=False):\n",
    "        self.return_dX = return_dX\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = X\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_prev, weights_prev):\n",
    "        \"\"\"\n",
    "        d_prev: gradient of J respect to A[l+1] of the previous layer according backward direction.\n",
    "        weights_prev: the weights of previous layer according backward direction.\n",
    "        \"\"\"\n",
    "        if self.return_dX:\n",
    "            return d_prev.dot(weights_prev.T)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(LearnableLayer):\n",
    "\n",
    "    def __init__(self, num_neurons, weight_init=\"std\"):\n",
    "        \"\"\"\n",
    "        The fully connected layer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_neurons: (integer) number of neurons in the layer.     \n",
    "        weight_init: (string) either `he_normal`, `xavier_normal`, `he_uniform`, `xavier_uniform` or standard normal distribution.\n",
    "        \"\"\"\n",
    "        assert weight_init in [\"std\", \"he_normal\", \"xavier_normal\", \"he_uniform\", \"xavier_uniform\"],\\\n",
    "                \"Unknow weight initialization type.\"\n",
    "        self.num_neurons = num_neurons\n",
    "        self.weight_init = weight_init\n",
    "        self.output = None\n",
    "        self.W = None\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Layer forward level. \n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs: inputs of the current layer. This is equivalent to the output of the previous layer.\n",
    "        Returns\n",
    "        -------\n",
    "        output: Output value LINEAR of the current layer.\n",
    "        \"\"\"\n",
    "        if self.W is None:\n",
    "            self.W = initialization_mapping[self.weight_init](weight_shape=(inputs.shape[1], self.num_neurons))\n",
    "        self.output = inputs.dot(self.W)\n",
    "        return self.output\n",
    "\n",
    "    def backward_layer(self, d_prev, _):\n",
    "        \"\"\"\n",
    "        Compute gradient w.r.t X only.\n",
    "        \"\"\"\n",
    "        d_prev = d_prev.dot(self.W.T)\n",
    "        return d_prev\n",
    "\n",
    "    def backward(self, d_prev, prev_layer):\n",
    "        \"\"\"\n",
    "        Layer backward level. Compute gradient respect to W and update it.\n",
    "        Also compute gradient respect to X for computing gradient of previous\n",
    "        layers as the forward direction [l-1].\n",
    "        Parameters\n",
    "        ----------\n",
    "        d_prev: gradient of J respect to A[l+1] of the previous layer according backward direction.\n",
    "        prev_layer: previous layer according forward direction.\n",
    "        Returns\n",
    "        -------\n",
    "        d_prev: gradient of J respect to A[l] at the current layer.\n",
    "        \"\"\"\n",
    "        dW = prev_layer.output.T.dot(d_prev)\n",
    "        d_prev = self.backward_layer(d_prev, None)\n",
    "        return d_prev, dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(Layer):\n",
    "\n",
    "    \"\"\"\n",
    "    Refer to the paper: \n",
    "        http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keep_prob):\n",
    "        \"\"\"\n",
    "        keep_prob: (float) probability to keep neurons in network, use for dropout technique.\n",
    "        \"\"\"\n",
    "        assert 0.0 < keep_prob < 1.0, \"keep_prob must be in range [0, 1].\"\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "    def forward(self, X, prediction=False):\n",
    "        \"\"\"\n",
    "        Drop neurons random uniformly.\n",
    "        \"\"\"\n",
    "        self.mask = np.random.uniform(size=X.shape) < self.keep_prob\n",
    "        self.output = X * self.mask\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_prev, _):\n",
    "        \"\"\"\n",
    "        Flow gradient of previous layer [l+1] according backward direction through dropout layer.\n",
    "        \"\"\"\n",
    "        return d_prev * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "\n",
    "    def __init__(self, activation):\n",
    "        \"\"\"\n",
    "        activation: (string) available activation functions. Must be in [sigmoid, tanh,\n",
    "                                relu, softmax]. Softmax activation must be at the last layer.\n",
    "        \n",
    "        \"\"\"\n",
    "        assert activation in [\"sigmoid\", \"tanh\", \"relu\", \"softmax\"], \"Unknown activation function: \" + str(activation)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Activation layer forward propgation.\n",
    "        \"\"\"\n",
    "        self.output = eval(self.activation)(X)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_prev, _):\n",
    "        \"\"\"\n",
    "        Activation layer backward propagation.\n",
    "        Parameters\n",
    "        ---------- \n",
    "        d_prev: gradient of J respect to A[l+1] of the previous layer according backward direction.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Gradient of J respect to type of activations (sigmoid, tanh, relu) in this layer `l`.\n",
    "        \"\"\"\n",
    "        d_prev = d_prev * eval(self.activation + \"_grad\")(self.output)\n",
    "        return d_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    \n",
    "    def __init__(self, weights=1, epsilon=1e-20):\n",
    "        self.weights = 1\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def __call__(self, Y_hat, Y):\n",
    "        \"\"\"\n",
    "        Compute cross-entropy loss.\n",
    "        Parameters\n",
    "        ----------\n",
    "        Y: one-hot encoding label. shape=(num_dataset, num_classes)\n",
    "        Y_hat: softmax probability distribution over each data point. \n",
    "            shape=(num_dataset, num_classes)\n",
    "        Returns\n",
    "        -------\n",
    "        J: cross-entropy loss.\n",
    "        \"\"\"\n",
    "        assert Y.shape == Y_hat.shape, \"Unmatch shape.\"\n",
    "        Y_hat[Y_hat == 0] = self.epsilon\n",
    "        loss = np.sum(self.weights * Y * np.log(Y_hat), axis=-1)\n",
    "        return -np.mean(loss)\n",
    "\n",
    "    def backward(self, Y_hat, Y):\n",
    "        \"\"\"\n",
    "        Compute gradient of CE w.r.t linear (LINEAR -> SOFTMAX -> CE)\n",
    "        Parameters\n",
    "        ----------\n",
    "        Y: one-hot encoding label. shape=(num_dataset, num_classes)\n",
    "        Y_hat: softmax probability distribution over each data point. \n",
    "            shape=(num_dataset, num_classes)\n",
    "        Returns\n",
    "        -------\n",
    "        grad CE w.r.t LINEAR\n",
    "        \"\"\"\n",
    "        m = Y.shape[0]\n",
    "        return (Y_hat - Y)/m\n",
    "\n",
    "class MSE:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Mean squared error\n",
    "        \"\"\"\n",
    "        m = len(y)\n",
    "        loss = np.sum((y_hat - y)**2)/(2*m)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, y_hat, y):\n",
    "        \"\"\"\n",
    "        Compute gradient of MSE w.r.t y_hat\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_hat: output from linear transformation. shape = (num_dataset, )\n",
    "        y: ground truth, real values. shape = (num_dataset, )\n",
    "        \"\"\"\n",
    "        m = len(y)\n",
    "        grad = (y_hat - y)/m\n",
    "        return grad\n",
    "\n",
    "class BinaryCrossEntropy:\n",
    "    \n",
    "    def __init__(self, epsilon=1e-10):\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def __call__(self, y_hat, y):\n",
    "        m = len(y_hat)\n",
    "        y_hat[y_hat == 0] = self.epsilon\n",
    "        y_hat[y_hat == 1] = 1 - self.epsilon\n",
    "        loss = -np.mean(y*np.log(y_hat) + (1-y)*np.log(1 - y_hat))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, y_hat, y):\n",
    "        m = len(y)\n",
    "        grad = (y_hat - y)/m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizers_: \n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def step(self, grads, layers):\n",
    "        raise NotImplementedError(\"step() function not defined\")\n",
    "\n",
    "class SGD(Optimizers_):\n",
    "\n",
    "    def __init__(self, alpha=0.01):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def step(self, grads, layers):\n",
    "        for grad, layer in zip(grads, layers):\n",
    "            layer.update_params(grad)\n",
    "\n",
    "class SGDMomentum(Optimizers_):\n",
    "\n",
    "    def __init__(self, alpha=0.01, beta=0.9):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.v = []\n",
    "    \n",
    "    def step(self, grads, layers):\n",
    "        if len(self.v) == 0:\n",
    "            self.v = [np.zeros_like(grad) for grad in grads]\n",
    "        for i, (grad, layer) in enumerate(zip(grads, layers)):\n",
    "            self.v[i] = self.beta*self.v[i] + (1-self.beta)*grad\n",
    "            grad = self.alpha * self.v[i]\n",
    "            layer.update_params(grad)\n",
    "\n",
    "class RMSProp(Optimizers_):\n",
    "\n",
    "    def __init__(self, alpha=0.01, beta=0.9, epsilon=1e-9):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        self.s = []\n",
    "\n",
    "    def step(self, grads, layers):\n",
    "        if len(self.s) == 0:\n",
    "            self.s = [np.zeros_like(grad) for grad in grads]\n",
    "        for i, (grad, layer) in enumerate(zip(grads, layers)):\n",
    "            self.s[i] = self.beta*self.s[i] + (1-self.beta)*grad**2\n",
    "            grad = self.alpha * (grad/(np.sqrt(self.s[i]) + self.epsilon))\n",
    "            layer.update_params(grad)\n",
    "\n",
    "class Adam(Optimizers_):\n",
    "    \n",
    "    def __init__(self, alpha=0.01, beta_1=0.9, beta_2=0.99, epsilon=1e-9):\n",
    "        self.alpha = alpha\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = epsilon\n",
    "        self.v = []\n",
    "        self.s = []\n",
    "        self.t = 1\n",
    "\n",
    "    def step(self, grads, layers):\n",
    "        if len(self.s) == 0 and len(self.v) == 0:\n",
    "            self.v = [np.zeros_like(grad) for grad in grads]\n",
    "            self.s = [np.zeros_like(grad) for grad in grads]\n",
    "        for i, (grad, layer) in enumerate(zip(grads, layers)):\n",
    "            self.v[i] = (self.beta_1*self.v[i] + (1-self.beta_1)*grad)\n",
    "            self.s[i] = (self.beta_2*self.s[i] + (1-self.beta_2)*grad**2)\n",
    "            v_correct = self.v[i] / (1-self.beta_1**self.t)\n",
    "            s_correct = self.s[i] / (1-self.beta_2**self.t)\n",
    "            grad = self.alpha * (v_correct / (np.sqrt(s_correct) + self.epsilon))\n",
    "            layer.update_params(grad)\n",
    "        self.t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, optimizer:object, layers:list, loss_func:object=CrossEntropy()):\n",
    "        \"\"\"\n",
    "        Deep neural network architecture.\n",
    "        Parameters\n",
    "        ----------\n",
    "        optimizer: (object) optimizer object uses to optimize the loss.\n",
    "        layers: (list) a list of sequential layers. For neural network, it should have [Dense, Activation, BatchnormLayer, Dropout]\n",
    "        loss_func: (object) the type of loss function we want to optimize. \n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_func = loss_func\n",
    "        self.layers = layers\n",
    "\n",
    "    def _forward(self, train_X, prediction=False):\n",
    "        \"\"\"\n",
    "        NN forward propagation level.\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_X: training dataset X.\n",
    "                shape = (N, D)\n",
    "        prediction: whether this forward pass is prediction stage or training stage.\n",
    "        Returns\n",
    "        -------\n",
    "        Probability distribution of softmax at the last layer.\n",
    "            shape = (N, C)\n",
    "        \"\"\"\n",
    "        inputs = train_X\n",
    "        layers = self.layers\n",
    "        if hasattr(self, \"output_layers\"):\n",
    "            layers = layers + self.output_layers\n",
    "        for layer in layers:\n",
    "            if isinstance(layer, (Dropout)):\n",
    "                inputs = layer.forward(inputs, prediction=prediction)\n",
    "                continue\n",
    "            inputs = layer.forward(inputs)\n",
    "        output = inputs\n",
    "        return output\n",
    "\n",
    "    def _backward_last(self, Y, Y_hat):\n",
    "        \"\"\"\n",
    "        Special formula of backpropagation for the last layer.\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"output_layers\"):\n",
    "            self.output_layers = self.layers[-2:]\n",
    "            self.layers = self.layers[:-2]\n",
    "            self.learnable_layers = [layer for layer in self.layers if isinstance(layer, LearnableLayer)]\n",
    "            self.learnable_layers.extend(layer for layer in self.output_layers if isinstance(layer, LearnableLayer))\n",
    "            self.learnable_layers = self.learnable_layers[::-1]\n",
    "\n",
    "        delta = self.loss_func.backward(Y_hat, Y)\n",
    "        dW_last = self.layers[-1].output.T.dot(delta)\n",
    "        dA_last = delta.dot(self.output_layers[0].W.T)\n",
    "        return dA_last, dW_last\n",
    "\n",
    "    def _backward(self, dA_last, dW_last):\n",
    "        \"\"\"\n",
    "        NN backward propagation level. Update weights of the neural network.\n",
    "        \"\"\"\n",
    "        dA_prev, dW = dA_last, dW_last\n",
    "        grads = [dW]\n",
    "        if dW is None:\n",
    "            grads.pop()\n",
    "        for i in range(len(self.layers)-1, 0, -1):\n",
    "            if isinstance(self.layers[i], LearnableLayer):\n",
    "                dA_prev, dW = self.layers[i].backward(dA_prev, self.layers[i-1])\n",
    "                grads.append(dW)\n",
    "                continue\n",
    "            dA_prev = self.layers[i].backward(dA_prev, self.layers[i-1])\n",
    "        return grads\n",
    "    \n",
    "    def _update_params(self, grads):\n",
    "        self.optimizer.step(grads, self.learnable_layers )\n",
    "\n",
    "    def backward(self, Y, Y_hat, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        Y: one-hot encoding label.\n",
    "            shape = (N, C).\n",
    "        Y_hat: output values of forward propagation NN.\n",
    "            shape = (N, C).\n",
    "        X: training dataset.\n",
    "            shape = (N, D).\n",
    "        \"\"\"\n",
    "        dA_last, dW_last = self._backward_last(Y, Y_hat)\n",
    "        grads = self._backward(dA_last, dW_last)\n",
    "        self._update_params(grads)\n",
    "\n",
    "    def __call__(self, X, prediction=False):\n",
    "        return self._forward(X, prediction)\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        \"\"\"\n",
    "        Predict function.\n",
    "        \"\"\"\n",
    "        y_hat = self._forward(test_X, prediction=True)\n",
    "        return np.argmax(y_hat, axis=1)\n",
    "    \n",
    "    def fit(self, X_train, y_train, validation, batch_size, epochs):\n",
    "        m = X_train.shape[0]\n",
    "        X_val, y_val = validation\n",
    "        train_losses, val_losses = [],[]\n",
    "\n",
    "        for e in range(epochs):\n",
    "            indices = np.random.permutation(m)\n",
    "            X_train = X_train[indices]\n",
    "            y_train = y_train[indices]\n",
    "            epoch_loss, val_loss = 0.0, 0.0\n",
    "            num_batches = 0\n",
    "            pbar = tqdm(range(0, X_train.shape[0], batch_size), desc=\"Epoch \" + str(e+1))\n",
    "\n",
    "            for it in pbar:\n",
    "                X_batch = X_train[it:it+batch_size]\n",
    "                y_batch = y_train[it:it+batch_size]\n",
    "                \n",
    "                y_hat = self._forward(X_batch)\n",
    "                batch_loss = self.loss_func(y_hat, y_batch)\n",
    "                self.backward(y_batch, y_hat, X_batch)\n",
    "\n",
    "                epoch_loss += batch_loss\n",
    "                num_batches += 1\n",
    "                pbar.set_description(\"Epoch \" + str(e+1) + \" - Loss: %.5f\" % (epoch_loss/num_batches))\n",
    "            y_val_hat = self._forward(X_val)\n",
    "            val_loss = self.loss_func(y_val, y_val_hat)\n",
    "            train_losses.append(epoch_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            print(\"Loss at epoch %d: %.5f - Validation loss: %.5f\" % (e+1, epoch_loss/num_batches, val_loss))\n",
    "        return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00deec39a9c488b999800e7373b3b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 1: 1.07482 - Validation loss: 11.66551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f840bebdf64c71a7c905620e22b17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 2: 1.02158 - Validation loss: 11.45884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95472044f47743d9ade72126633c8492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 3: 0.95255 - Validation loss: 11.54671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb81ef4f6f0478fb6d5666e2167448f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 4: 0.89405 - Validation loss: 11.27387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef357bcc5d041ffb18ea47c92d92465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 5: 0.85643 - Validation loss: 11.13681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5df37e13671467db837e7bf494f681a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 6', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 6: 0.80585 - Validation loss: 11.16004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0619e98262493e9e88c95b4ae01eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 7', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 7: 0.76947 - Validation loss: 10.77795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b1bd91be6e48019598ff2d79246410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 8', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 8: 0.73649 - Validation loss: 10.67007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceef6c41e7d64541a6bb5160ec0a905d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 9', max=45.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 9: 0.70603 - Validation loss: 10.68488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3b908a16fc43da8c54a16a1c63b342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 10: 0.68890 - Validation loss: 10.10311\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846b45893c1946f48cc2842339059292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 11: 0.65542 - Validation loss: 10.23795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cf33a74b5b4d2d951c23da9b2c1aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 12', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 12: 0.64381 - Validation loss: 10.08901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4ad49d3a564d31aab7b2edc61b0e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 13', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 13: 0.62512 - Validation loss: 9.83415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0507da203ff5471890e837b62e45d02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 14', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 14: 0.60101 - Validation loss: 9.63360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70936077522c42288587f8d38734cc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 15', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 15: 0.59654 - Validation loss: 9.43304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb67fab603c8447a92bda8725fd7dd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 16', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 16: 0.57910 - Validation loss: 9.45777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c17707eb06842c3b29e009e45a577df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 17', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 17: 0.55333 - Validation loss: 9.43257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da6428d684a49a99d6fc3c5ed77fb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 18', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 18: 0.54698 - Validation loss: 9.16126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b3a95f73af4de68a0c06ccbbbd5361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 19', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 19: 0.53508 - Validation loss: 8.85340\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6299ce71d0c14a3ba0ed8002eb8e7194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 20', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 20: 0.53327 - Validation loss: 8.80965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41669b2231b34b3c869bff9797126ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 21', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 21: 0.52343 - Validation loss: 8.32752\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1aed4f535cb427ba1401fe4590551a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 22', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 22: 0.53025 - Validation loss: 8.37300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed28076a86945d18745149afcf54962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 23', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 23: 0.51845 - Validation loss: 8.49814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06513a6918f64374bb720a45eace4922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 24', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 24: 0.51710 - Validation loss: 8.39196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d69cc8fad648d496e70eb565189421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 25', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 25: 0.49793 - Validation loss: 8.39962\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae69465366954d479a3911c948ef5e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 26', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 26: 0.48027 - Validation loss: 8.26956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b9767b3eef4c7e885fa4867fee6038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 27', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 27: 0.50291 - Validation loss: 8.30921\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0feaef21c6e44b5fad024d5267c89293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 28', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 28: 0.48172 - Validation loss: 8.12335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cd232f0f694bf891087dbc8d370e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 29', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 29: 0.49210 - Validation loss: 7.99067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d7617defdb4b4b8c9e0f30426946ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 30', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 30: 0.48369 - Validation loss: 7.64661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd4968b0f2f49c190a36ec3b8912972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 31', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 31: 0.47285 - Validation loss: 7.56948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa7ad24fb0f4de5acdff0b9854d544b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 32', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 32: 0.47482 - Validation loss: 7.69860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a6378957b04a129761cb6ea052537c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 33', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 33: 0.46974 - Validation loss: 7.64274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d337fdb34e4449a13bdb40933fea58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 34', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 34: 0.47329 - Validation loss: 7.38191\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1079123d0647c6952b1b30f83bd101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 35', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 35: 0.47389 - Validation loss: 7.59626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a39562763b4e6d9caa171cc1268eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 36', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 36: 0.45414 - Validation loss: 7.36507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd34ef8195f41b39b6f3296cde7be62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 37', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 37: 0.46893 - Validation loss: 7.38395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7de39ae00845709eb48d08b1cccdf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 38', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 38: 0.46394 - Validation loss: 7.37440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cf7435b16a49d9932703d0a5ea3768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 39', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 39: 0.46468 - Validation loss: 7.35886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5638ec04464dbf917702a88abd9852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 40', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 40: 0.45322 - Validation loss: 7.25213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ad382188fe43c98df72e706cd91214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 41', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 41: 0.45665 - Validation loss: 7.18472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ad92d5a3864545adf3566827182d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 42', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 42: 0.45632 - Validation loss: 7.16456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003722d010ee46f59bdf07c7d8ed00b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 43', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 43: 0.45068 - Validation loss: 7.05125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e20e93bd51430099c7a470b1666f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 44', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 44: 0.45973 - Validation loss: 7.06639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5a19247fa44c058f5ca35e049ef244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 45', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 45: 0.45489 - Validation loss: 7.03010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0bdaf95a604f73bf6917dd5c851e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 46', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 46: 0.46146 - Validation loss: 7.19828\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b95e3b779b0443b97c246367e277e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 47', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 47: 0.44041 - Validation loss: 7.02917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d25ee7e2af450d96fb3232faae4c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 48', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 48: 0.44839 - Validation loss: 7.11427\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9bbb582c1b43e1a9bd6f90bc12199b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 49', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 49: 0.45811 - Validation loss: 7.02493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d336c5fc6043bb9d77fe7af2264735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 50', max=45.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss at epoch 50: 0.45459 - Validation loss: 7.14459\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(0.0001)\n",
    "loss_func = BinaryCrossEntropy()\n",
    "archs = [\n",
    "    Input(),\n",
    "    Dense(num_neurons=128, weight_init=\"he_normal\"),\n",
    "    Activation(activation=\"relu\"),\n",
    "    Dropout(keep_prob=0.5),\n",
    "    Dense(num_neurons=8, weight_init=\"he_normal\"),\n",
    "    Activation(activation=\"sigmoid\"),\n",
    "    Dense(num_neurons=2, weight_init=\"he_normal\"),\n",
    "    Activation(activation=\"softmax\"),\n",
    "]\n",
    "\n",
    "val_set = (val_X, enc.transform(val_Y).toarray())\n",
    "\n",
    "model = Model(optimizer=optimizer, layers=archs, loss_func=loss_func)\n",
    "train_losses, val_losses = model.fit(train_X, train_Y, val_set, batch_size=16, epochs=50)\n",
    "\n",
    "import pickle\n",
    "with open(\"nn_weights.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8100558659217877\n",
      "Confusion matrix: \n",
      "[[89  9]\n",
      " [25 56]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"nn_weights.pkl\", \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "pred = model.predict(val_X)\n",
    "# val_Y = enc.inverse_transform(val_Y).reshape(val_Y.shape[0])\n",
    "print(\"Accuracy:\", len(pred[val_Y.reshape(val_Y.shape[0]) == pred]) / len(pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix: \")\n",
    "print(confusion_matrix(val_Y.reshape(val_Y.shape[0]), pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm tra (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Đọc dữ liệu tập kiểm tra vào data frame `test_input_df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 10 columns):\n",
      "Pclass      418 non-null int64\n",
      "Name        418 non-null object\n",
      "Sex         418 non-null object\n",
      "Age         332 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Ticket      418 non-null object\n",
      "Fare        417 non-null float64\n",
      "Cabin       91 non-null object\n",
      "Embarked    418 non-null object\n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 35.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                       \n",
       "892          34.5      0      0   330911   7.8292   NaN        Q  \n",
       "893          47.0      1      0   363272   7.0000   NaN        S  \n",
       "894          62.0      0      0   240276   9.6875   NaN        Q  \n",
       "895          27.0      0      0   315154   8.6625   NaN        S  \n",
       "896          22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_df = pd.read_csv('test.csv', index_col=0)\n",
    "test_input_df.info()\n",
    "test_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_charaters(name):\n",
    "    if '\"' in name:\n",
    "        return re.sub('\"', '', name)\n",
    "\n",
    "# test_input_df['Name'] = test_input_df['Name'].apply(remove_special_charaters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Xây dựng `test_X` từ `test_input_df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 24 columns):\n",
      "Pclass           418 non-null int64\n",
      "Age              418 non-null float64\n",
      "SibSp            418 non-null int64\n",
      "Parch            418 non-null int64\n",
      "female           418 non-null float64\n",
      " Mr              418 non-null float64\n",
      " Master          418 non-null float64\n",
      " Mrs             418 non-null float64\n",
      " Miss            418 non-null float64\n",
      " Dr              418 non-null float64\n",
      " Rev             418 non-null float64\n",
      " Don             418 non-null float64\n",
      " Col             418 non-null float64\n",
      " Jonkheer        418 non-null float64\n",
      " Ms              418 non-null float64\n",
      " Mlle            418 non-null float64\n",
      " Mme             418 non-null float64\n",
      " the Countess    418 non-null float64\n",
      " Major           418 non-null float64\n",
      " Lady            418 non-null float64\n",
      " Capt            418 non-null float64\n",
      "C                418 non-null float64\n",
      "Q                418 non-null float64\n",
      "Fare             418 non-null float64\n",
      "dtypes: float64(21), int64(3)\n",
      "memory usage: 101.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_X = process_new_input_df(test_input_df, dropped_cols, mean_mode_dict, X_mean, X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Dự đoán nhãn lớp của test_X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nn_weights.pkl\", \"rb\") as f:\n",
    "            nn = pickle.load(f)\n",
    "        \n",
    "# Predict\n",
    "preds = nn.predict(test_X)\n",
    "preds_df = pd.DataFrame(preds, index=test_input_df.index, columns=['Survived'])\n",
    "preds_df.head()\n",
    "preds_df.to_csv('preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "*submit file `preds.csv` lên [Kaggle](https://www.kaggle.com/c/titanic/submissions/attach), và ghi nhận lại độ chính xác.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả cho single model MLP from Scratch: ```Your submission scored 0.80622```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
