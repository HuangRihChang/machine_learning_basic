{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='lightgreen'>Data Science</font>\n",
    "## <font color='green'>BT06: Titanic</font>\n",
    "\n",
    "### Hoàng Nhật Sương - 1412470\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tổng thể\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này; trong file, mình đã để từ `TODO` để cho biết những chỗ mà bạn cần phải làm (trong đó, `TODO` đầu tiên là bạn phải ghi họ tên và MSSV vào phần đầu của file). Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "Nên nhớ mục tiêu chính ở đây là *học, học một cách chân thật*. Bạn có thể thảo luận ý tưởng với bạn khác cũng như là tham khảo các tài liệu, nhưng *code và bài làm phải là của bạn, dựa trên sự hiểu của bạn*. Nếu vi phạm thì sẽ bị 0 điểm cho toàn bộ môn học.\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Trước khi nộp bài, bạn chọn `Kernel` -> `Restart & Run All` (restart python và chạy tất cả các cell), rồi kiểm tra xem có bị lỗi gì không.\n",
    "\n",
    "Sau đó, trong thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`) bạn đặt file: `BT06-Titanic.ipynb`, `train.csv`, `val.csv`, `test.csv`; rồi nén thư mục `MSSV` này lại và nộp ở link trên moodle.\n",
    "\n",
    "**Nội dung bài tập**\n",
    "\n",
    "Trong bài này, bạn sẽ thực hành: (i) tiền xử lý dữ liệu, và (ii) huấn luyện Neural Net với weight decay và early stopping. Bộ dữ liệu được sử dụng là bộ [Kaggle Titanic](https://www.kaggle.com/c/titanic); trong đó, đầu vào là thông tin của hành khách trên tàu Titanic (bạn xem chi tiết trong file `description.txt` đính kèm), đầu ra là một trong hai lớp sống/chết (1/0). Mình có đính kèm các file dữ liệu: `train.csv` - tập huấn luyện, `val.csv` - tập validation, `test.csv` - tập kiểm tra (chỉ có đầu vào); thật ra, Kaggle chỉ cung cấp hai file là `train.csv` và `test.csv`, mình đã tách file `train.csv` của Kaggle ra hai file là `train.csv` (80%) và `val.csv` (20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import cPickle\n",
    "# You can also import other things ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đọc dữ liệu tập huấn luyện và tập validation vào data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 11 columns):\n",
      "Survived    712 non-null int64\n",
      "Pclass      712 non-null int64\n",
      "Name        712 non-null object\n",
      "Sex         712 non-null object\n",
      "Age         574 non-null float64\n",
      "SibSp       712 non-null int64\n",
      "Parch       712 non-null int64\n",
      "Ticket      712 non-null object\n",
      "Fare        712 non-null float64\n",
      "Cabin       160 non-null object\n",
      "Embarked    711 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 66.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Yousseff, Mr. Gerious</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2627</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Willey, Mr. Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O./P.P. 751</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eric</td>\n",
       "      <td>male</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Spencer, Mrs. William Augustus (Marie Eugenie)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17569</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>B78</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Touma, Mrs. Darwis (Hanne Youssef Razi)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2650</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                                            Name  \\\n",
       "PassengerId                                                                     \n",
       "496                 0       3                           Yousseff, Mr. Gerious   \n",
       "649                 0       3                              Willey, Mr. Edward   \n",
       "279                 0       3                              Rice, Master. Eric   \n",
       "32                  1       1  Spencer, Mrs. William Augustus (Marie Eugenie)   \n",
       "256                 1       3         Touma, Mrs. Darwis (Hanne Youssef Razi)   \n",
       "\n",
       "                Sex   Age  SibSp  Parch         Ticket      Fare Cabin  \\\n",
       "PassengerId                                                              \n",
       "496            male   NaN      0      0           2627   14.4583   NaN   \n",
       "649            male   NaN      0      0  S.O./P.P. 751    7.5500   NaN   \n",
       "279            male   7.0      4      1         382652   29.1250   NaN   \n",
       "32           female   NaN      1      0       PC 17569  146.5208   B78   \n",
       "256          female  29.0      0      2           2650   15.2458   NaN   \n",
       "\n",
       "            Embarked  \n",
       "PassengerId           \n",
       "496                C  \n",
       "649                S  \n",
       "279                Q  \n",
       "32                 C  \n",
       "256                C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "train_df.info()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 529 to 685\n",
      "Data columns (total 11 columns):\n",
      "Survived    179 non-null int64\n",
      "Pclass      179 non-null int64\n",
      "Name        179 non-null object\n",
      "Sex         179 non-null object\n",
      "Age         140 non-null float64\n",
      "SibSp       179 non-null int64\n",
      "Parch       179 non-null int64\n",
      "Ticket      179 non-null object\n",
      "Fare        179 non-null float64\n",
      "Cabin       44 non-null object\n",
      "Embarked    178 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 16.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Salonen, Mr. Johan Werner</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3101296</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363592</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Kimball, Mr. Edwin Nelson Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11753</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Morley, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364506</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Boulos, Mr. Hanna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2664</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                          Name   Sex   Age  \\\n",
       "PassengerId                                                               \n",
       "529                 0       3     Salonen, Mr. Johan Werner  male  39.0   \n",
       "697                 0       3              Kelly, Mr. James  male  44.0   \n",
       "622                 1       1  Kimball, Mr. Edwin Nelson Jr  male  42.0   \n",
       "462                 0       3           Morley, Mr. William  male  34.0   \n",
       "599                 0       3             Boulos, Mr. Hanna  male   NaN   \n",
       "\n",
       "             SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                 \n",
       "529              0      0  3101296   7.9250   NaN        S  \n",
       "697              0      0   363592   8.0500   NaN        S  \n",
       "622              1      0    11753  52.5542   D19        S  \n",
       "462              0      0   364506   8.0500   NaN        S  \n",
       "599              0      0     2664   7.2250   NaN        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv('val.csv', index_col=0)\n",
    "val_df.info()\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Tiền xử lý tập huấn luyện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_df = train_df.iloc[:, 1:]\n",
    "train_output_df = train_df.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. Xây dựng `train_X` từ `train_input_df`**\n",
    "\n",
    "(`train_X` là mảng numpy chứa các véc-tơ đầu vào mà có thể đưa trực tiếp vào mô hình học như ở các bài tập trước.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, ta sẽ tiến hành: \n",
    "- Bỏ cột `Cabin` vì cột này có nhiều giá thiếu (552/712) (và có vẻ cột này sẽ không giúp ích được gì nhiều cho việc dự đoán sống/chết).\n",
    "- Bỏ cột `Ticket` vì cột này có giá trị không phải dạng số, sẽ cần phải tốn sức để chuyển sang dạng số (và có vẻ cột này cũng sẽ không giúp ích được gì nhiều cho việc dự đoán sống/chết).\n",
    "- Bỏ cột `Name` vì cột này có giá trị không phải dạng số, sẽ cần phải tốn sức để chuyển sang dạng số. Lưu ý là, việc bỏ cột `Name` có thể sẽ làm mất mát thông tin cần thiết để dự đoán sống/chết (vì trong cột `Name` có các từ như là `Miss`, `Mrs`, `Mr`, ... có thể sẽ có ích cho việc dự đoán); tuy nhiên, ở đây, để đơn giản, ta bỏ luôn :-)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 7 columns):\n",
      "Pclass      712 non-null int64\n",
      "Sex         712 non-null object\n",
      "Age         574 non-null float64\n",
      "SibSp       712 non-null int64\n",
      "Parch       712 non-null int64\n",
      "Fare        712 non-null float64\n",
      "Embarked    711 non-null object\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 44.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dropped_cols = ['Name', 'Ticket', 'Cabin']\n",
    "train_input_df.drop(dropped_cols, axis=1, inplace=True)\n",
    "train_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kế đến, ta sẽ xử lý các giá trị thiếu ở cột `Age` và cột `Embarked`. Ở đây, ta xử lý đơn giản là điền giá trị mean (giá trị trung bình) vào các giá trị thiếu ở cột `Age`, và điền giá trị mode (giá trị xuất hiện nhiều nhất) vào các giá trị thiếu ở cột `Embarked`. *Lưu ý là, khi điền các giá trị thiếu ở tập validation/test, ta sẽ sử dụng các giá trị mean/mode được tính từ tập huấn luyện*. Trong thực tế,  ta thường sẽ không biết ở thời điểm test biến đầu vào nào sẽ thiếu giá trị; do đó, ta có thể làm một cách tổng quát như sau: với biến đầu vào có giá trị số, ta sẽ điền giá trị mean; ngược lại, điền giá trị mode. Dưới đây, hàm `compute_mean_mode` sẽ tính từ tập huấn luyện giá trị mean/mode của *tất cả* các biến đầu vào; hàm `fill_missing_values` sẽ dùng các giá trị mean/mode này để điền giá trị thiếu cho một tập dữ liệu nào đó (tập huấn luyện/validation/kiểm tra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_mean_mode(train_input_df):\n",
    "    '''\n",
    "    Computes means for numeric input variables and modes for non-numeric ones.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_input_df : data frame\n",
    "        The data frame containing training inputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_mode_dict : dictionary, len = # input variables (# columns) of train_input_df\n",
    "        mean_mode_dict[<column_name>] = mean/mode of this column.\n",
    "    '''\n",
    "    # TODO\n",
    "    dic = {}\n",
    "    for column in train_input_df:\n",
    "        num = 0\n",
    "        for i in range(7000):\n",
    "            try:\n",
    "                a = train_input_df.loc[i][column]\n",
    "                num = i\n",
    "                break\n",
    "            except:\n",
    "                next\n",
    "        if (isinstance(train_input_df.loc[num][column], (str, unicode))):\n",
    "            dic[column] = str(train_input_df[column].mode()[0])\n",
    "        else:\n",
    "            dic[column] = train_input_df[column].mean()\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 29.488815331010457,\n",
       " 'Embarked': 'S',\n",
       " 'Fare': 32.18301095505614,\n",
       " 'Parch': 0.37359550561797755,\n",
       " 'Pclass': 2.3230337078651684,\n",
       " 'Sex': 'male',\n",
       " 'SibSp': 0.5140449438202247}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_mode_dict = compute_mean_mode(train_input_df)\n",
    "mean_mode_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả của mình:\n",
    "\n",
    "`{'Age': 29.488815331010457,\n",
    " 'Embarked': 'S',\n",
    " 'Fare': 32.18301095505614,\n",
    " 'Parch': 0.37359550561797755,\n",
    " 'Pclass': 2.3230337078651684,\n",
    " 'Sex': 'male',\n",
    " 'SibSp': 0.5140449438202247}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_missing_values(input_df, mean_mode_dict):\n",
    "    '''\n",
    "    Fills missing values for ALL columns of `input_df` using `mean_mode_dict`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_df : data frame\n",
    "        The data frame containing inputs.\n",
    "    mean_mode_dict : dictionary\n",
    "        mean_mode_dict[<column_name>] = mean/mode of this column (estimated from the training set).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    filled_input_df : data frame\n",
    "        The data frame containing inputs after filling missing values.\n",
    "    '''\n",
    "    # TODO\n",
    "    for column in input_df:\n",
    "        df = input_df[pd.isnull(input_df).any(axis=1)]\n",
    "        index = df.index.get_values()\n",
    "        for i in index:\n",
    "            if(pd.isnull(input_df.loc[i, column])):\n",
    "                input_df.loc[i, column] = mean_mode_dict[column]\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\n",
      "496   NaN\n",
      "649   NaN\n",
      "32    NaN\n",
      "299   NaN\n",
      "368   NaN\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "PassengerId\n",
      "62    NaN\n",
      "Name: Embarked, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Before filling\n",
    "missing_age_mask = train_input_df.Age.isnull()\n",
    "missing_embarked_mask = train_input_df.Embarked.isnull()\n",
    "print train_input_df.Age[missing_age_mask].head()\n",
    "print\n",
    "print train_input_df.Embarked[missing_embarked_mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\n",
      "496    29.488815\n",
      "649    29.488815\n",
      "32     29.488815\n",
      "299    29.488815\n",
      "368    29.488815\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "PassengerId\n",
      "62    S\n",
      "Name: Embarked, dtype: object\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 7 columns):\n",
      "Pclass      712 non-null int64\n",
      "Sex         712 non-null object\n",
      "Age         712 non-null float64\n",
      "SibSp       712 non-null int64\n",
      "Parch       712 non-null int64\n",
      "Fare        712 non-null float64\n",
      "Embarked    712 non-null object\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 44.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Fill and check the result\n",
    "train_input_df = fill_missing_values(train_input_df, mean_mode_dict)\n",
    "print train_input_df.Age[missing_age_mask].head()\n",
    "print\n",
    "print train_input_df.Embarked[missing_embarked_mask].head()\n",
    "print\n",
    "train_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đến đây, ta đã bỏ các cột `Name`, `Ticket`, `Cabin`; và điền giá trị thiếu cho cột `Age`, `Embarked`. Kế đến, ta sẽ chuyển các cột có giá trị không phải dạng số (`Sex` và `Embarked`) sang dạng số. Vì `Sex` và `Embarked` là các biến có giá trị rời-rạc và không-có-thứ-tự nên ta có thể chuyển sang dạng \"one-hot\" (và bỏ cột cuối). Vd:\n",
    "\n",
    "```\n",
    "Sex    --> Female | Male\n",
    "------     --------------\n",
    "female --> 1      | 0\n",
    "male   --> 0      | 1\n",
    "female --> 1      | 0\n",
    "```\n",
    "và ta có thể bỏ cột `Male` đi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_categorical_cols(input_df):\n",
    "    '''\n",
    "    Converts `Sex` column and `Embarked` column to one-hot forms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_df : data frame\n",
    "        The data frame containing inputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numeric_input_df : data frame\n",
    "        The data frame containing inputs after converting.\n",
    "    '''\n",
    "    # TODO\n",
    "    sex_tag = ['female', 'male']\n",
    "    Embarked_tag = ['C','Q','S']\n",
    "    index = input_df.index.get_values()\n",
    "    value_sex = []\n",
    "    value_C = []\n",
    "    value_Q = []\n",
    "    \n",
    "    print len(input_df)\n",
    "    \n",
    "    try:\n",
    "        for i in range(len(index)):\n",
    "            if(input_df.loc[int(index[i])]['Sex'] == sex_tag[0]):\n",
    "                value_sex.append(1.0)\n",
    "            else:\n",
    "                value_sex.append(0.0)\n",
    "            if(input_df.loc[int(index[i])]['Embarked'] == Embarked_tag[0]):\n",
    "                value_C.append(1.0)\n",
    "            else:\n",
    "                value_C.append(0.0)\n",
    "            if(input_df.loc[int(index[i])]['Embarked'] == Embarked_tag[1]):\n",
    "                value_Q.append(1.0)\n",
    "            else:\n",
    "                value_Q.append(0.0)\n",
    "    \n",
    "        input_df.insert(6, 'female', value_sex, allow_duplicates = True)\n",
    "        input_df.insert(7, 'C', value_C, allow_duplicates = True)\n",
    "        input_df.insert(8, 'Q', value_Q, allow_duplicates = True)\n",
    "        input_df.drop('Sex', axis=1, inplace=True)\n",
    "        input_df.drop('Embarked', axis=1, inplace=True)\n",
    "    except:\n",
    "        return input_df\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 496 to 153\n",
      "Data columns (total 8 columns):\n",
      "Pclass    712 non-null int64\n",
      "Age       712 non-null float64\n",
      "SibSp     712 non-null int64\n",
      "Parch     712 non-null int64\n",
      "Fare      712 non-null float64\n",
      "female    712 non-null float64\n",
      "C         712 non-null float64\n",
      "Q         712 non-null float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 50.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_input_df = process_categorical_cols(train_input_df)\n",
    "train_input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả của mình:\n",
    "\n",
    "`<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 712 entries, 496 to 153\n",
    "Data columns (total 8 columns):\n",
    "Pclass    712 non-null int64\n",
    "Age       712 non-null float64\n",
    "SibSp     712 non-null int64\n",
    "Parch     712 non-null int64\n",
    "Fare      712 non-null float64\n",
    "female    712 non-null float64\n",
    "C         712 non-null float64\n",
    "Q         712 non-null float64\n",
    "dtypes: float64(5), int64(3)\n",
    "memory usage: 50.1 KB`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, ta sẽ xây dựng `train_X`. Để giúp Gradient Descent hội tụ nhanh hơn, ta sẽ chuẩn hóa để các cột của `train_X` có mean bằng 0 và có độ lệch chuẩn bằng 1. *Lưu ý là, khi chuẩn hóa `val_X`/`test_X`, ta sẽ dùng mean và độ lệch chuẩn được ước lượng từ tập huấn luyện.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712L, 8L)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_input_df.values\n",
    "print train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: compute `X_mean` and `X_std`\n",
    "X_mean = train_X.mean(axis=0)\n",
    "X_std = train_X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.32303371  29.48881533   0.51404494   0.37359551  32.18301096\n",
      "   0.3497191    0.17977528   0.08426966]\n",
      "[  0.83439261  13.12054565   1.0743822    0.80082787  52.29476578\n",
      "   0.47688117   0.38400017   0.2777918 ]\n"
     ]
    }
   ],
   "source": [
    "print X_mean\n",
    "print X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả của mình:\n",
    "\n",
    "`[  2.32303371  29.48881533   0.51404494   0.37359551  32.18301096\n",
    "   0.3497191    0.17977528   0.08426966]\n",
    "[  0.83439261  13.12054565   1.0743822    0.80082787  52.29476578\n",
    "   0.47688117   0.38400017   0.2777918 ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: normalize train_X using X_mean and X_std\n",
    "train_X = (train_X - X_mean)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.09570189e-16  -4.98976640e-18   1.24744160e-18  -4.24130144e-17\n",
      "  -5.48874304e-17   6.48669632e-17   2.49488320e-17   7.48464960e-18]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print train_X.mean(axis=0)\n",
    "print train_X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712L, 9L)\n"
     ]
    }
   ],
   "source": [
    "# Add x_0 column\n",
    "train_X = np.hstack([np.ones((len(train_X), 1)), train_X])\n",
    "print train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**1.2. Xây dựng `train_Y` từ `train_output_df`**\n",
    "\n",
    "(`train_Y` là mảng numpy chứa các đầu ra đúng mà có thể đưa trực tiếp vào mô hình học như ở các bài tập trước.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712L, 1L)\n"
     ]
    }
   ],
   "source": [
    "train_Y = train_output_df.values.reshape(-1, 1)\n",
    "print train_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Tiền xử lý tập validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_input_df = val_df.iloc[:, 1:]\n",
    "val_output_df = val_df.Survived\n",
    "len(val_input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. Xây dựng `val_X` từ `val_input_df`**\n",
    "\n",
    "Cách xây dựng `test_X` từ `test_input_df` sẽ *giống hệt* cách xây dựng `val_X` từ `val_input_df`. Do đó, ta sẽ viết phần xử lý này vào một hàm để lúc sau có thể dùng lại cho tập kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_new_input_df(new_input_df, dropped_cols, mean_mode_dict, X_mean, X_std):\n",
    "    '''\n",
    "    Builds `new_X` from `new_input_df`:\n",
    "    1. Drop columns using `dropped_cols` (`dropped_cols` is the list containing names of dropped columns)\n",
    "    2. Fill missing values using `mean_mode_dict` (use `fill_missing_values` function)\n",
    "    3. Convert categorial columns to one-hot (use `process_categorical_cols` function)\n",
    "    4. Subtract by `X_mean` and divide by `X_std`\n",
    "    5. Add `x_0` column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    I'm lazy now ...\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_X : numpy array\n",
    "        The matrix of input vectors.\n",
    "    '''\n",
    "    # TODO\n",
    "    new_input_df = new_input_df.drop(dropped_cols, axis=1)\n",
    "    new_input_df = fill_missing_values(new_input_df, mean_mode_dict)\n",
    "    new_input_df = process_categorical_cols(new_input_df)\n",
    "    print new_input_df.info()\n",
    "    new_X = new_input_df.values\n",
    "    new_X = (new_X - X_mean)/X_std\n",
    "    new_X = np.hstack([np.ones((len(new_X), 1)), new_X])\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 529 to 685\n",
      "Data columns (total 8 columns):\n",
      "Pclass    179 non-null int64\n",
      "Age       179 non-null float64\n",
      "SibSp     179 non-null int64\n",
      "Parch     179 non-null int64\n",
      "Fare      179 non-null float64\n",
      "female    179 non-null float64\n",
      "C         179 non-null float64\n",
      "Q         179 non-null float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 12.6 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179L, 9L)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = process_new_input_df(val_input_df, dropped_cols, mean_mode_dict, X_mean, X_std)\n",
    "val_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. Xây dựng `val_Y` từ `val_output_df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179L, 1L)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_Y = val_output_df.values.reshape(-1, 1)\n",
    "val_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm tính output của Neural Net** (giống hệt bài tập trước)\n",
    "\n",
    "Ở đây, ta dùng hàm kích hoạt sigmoid ở các tầng ẩn, và hàm softmax ở tầng cuối."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(S):\n",
    "    '''\n",
    "    Computes sigmoid function for each element of array S.\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-S))\n",
    "def softmax(S):\n",
    "    '''\n",
    "    Computes softmax function for each row of array S.\n",
    "    '''\n",
    "    A = np.exp(S)\n",
    "    A /= A.sum(axis=1, keepdims=True)\n",
    "    return A\n",
    "def compute_nnet_outputs(Ws, X, need_all_layer_outputs):\n",
    "    '''\n",
    "    Computes the outputs of Neural Net by forward propagating X through the net.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Ws : list of numpy arrays\n",
    "        Ws[l-1] is W of layer l with l >= 1 (layer 0 is input layer; it doesn't have W);\n",
    "        W of layer l will have the shape of (d^(l-1)+1, d^(l)), where \n",
    "        d^(l-1) is the number of neurons (not count the +1 neuron) of layer l-1 and \n",
    "        d^(l) is the number of neurons (not count the +1 neuron) of layer l.\n",
    "    X : numpy array, shape (N, d+1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); \n",
    "        the first column of this matrix is all ones (corresponding to x_0).\n",
    "    need_all_layer_outputs : bool\n",
    "        If this var is true, we'll return a list of layer's-outputs; \n",
    "        otherwise, we'll return the final layer's output.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    If `need_all_layer_outputs` is false, return\n",
    "        A : numpy array, shape (N, K=10)\n",
    "            The maxtrix of output vectors of final layer; each row is an output vector (containing \n",
    "            each class's probability given the corresponding input vector).\n",
    "    Else, return\n",
    "        As : list of numpy arrays\n",
    "            As[l] is the matrix of output vectors of layer l; each row is an output vector (corresponding \n",
    "            to an input vector).\n",
    "    '''    \n",
    "    # TODO\n",
    "    if(need_all_layer_outputs):\n",
    "        As = [X]\n",
    "    A = X;\n",
    "    \n",
    "    for i in range(len(Ws)):\n",
    "        S = A.dot(Ws[i])\n",
    "        if(i < len(Ws) - 1):\n",
    "            A = sigmoid(S);\n",
    "            A = np.hstack((np.ones((len(A),1)),A))\n",
    "        else:\n",
    "            A = softmax(S)\n",
    "        \n",
    "        if(need_all_layer_outputs):\n",
    "            As.append(A)\n",
    "    if(need_all_layer_outputs):\n",
    "        return As\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hàm huấn luyện Neural Net** (bổ sung weight decay và early stopping so với bài tập trước)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_nnet(train_X, train_Y, val_X, val_Y, hid_layer_sizes, wd_level,\n",
    "               mb_size, learning_rate, max_patience, max_epoch=1000000, momentum_param=0.):\n",
    "    '''\n",
    "    Trains Neural Net on the dataset (X, Y).\n",
    "    Cost function: mean negative log likelihood + weight decay.\n",
    "    Optimization algorithm: SGD; stopping criteria: early stopping and/or max epoch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, d + 1)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); \n",
    "        the first column of this matrix is all ones (corresponding to x_0).\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    hid_layer_sizes : list\n",
    "        The list of hidden layer sizes; e.g., hid_layer_sizes = [20, 10] means: \n",
    "        the Net has 2 hidden layers, the 1st one has 20 neurons, and the 2nd one has \n",
    "        10 neurons (not count the +1 neurons).\n",
    "    wd_level : float\n",
    "        The level (coefficient) of weight decay.\n",
    "    mb_size : int\n",
    "        Minibatch size of SGD.\n",
    "    learning_rate : float\n",
    "        Learning rate of SGD.\n",
    "    max_patience : int (> 0) or None\n",
    "        The parameter of early stopping. We'll have a `patience` variable with initial value equal to\n",
    "        `max_patience`. During the training, we'll keep track of the best MBE (Mean Binary Error) \n",
    "        on the validation set; if the MBE on the validation set at the current epoch < the current \n",
    "        best one, we'll reset `patience` to `max_patience`; otherwise, `patience` -= 1. \n",
    "        When `patience` = 0 or `max_epoch` is reached, we'll terminate SGD.\n",
    "        If `max_patience` is None, we don't use early stopping.\n",
    "    max_epoch : int, default 1000000\n",
    "        We'll terminate SGD after this number of epochs or when `patience` = 0 (if early stopping is used).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Ws : list of numpy arrays\n",
    "        Ws[l-1] is W of layer l with l >= 1 (layer 0 is input layer; it doesn't have W);\n",
    "        W of layer l will have the shape of (d^(l-1)+1, d^(l)), where \n",
    "        d^(l-1) is the number of neurons (not count the +1 neuron) of layer l-1 and \n",
    "        d^(l) is the number of neurons (not count the +1 neuron) of layer l.\n",
    "        *If `max_patience` is None, Ws are weights after the final epoch (as previous homeworks); \n",
    "        otherwise, Ws are weights corresponding to the best MBE on the validation set.*\n",
    "    train_errs : list, len = num epochs spent on training\n",
    "        The list of MBEs on the training set after each epoch.\n",
    "    val_errs : list, len = num epochs spent on training\n",
    "        The list of MBEs on the validation set after each epoch.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    After each *100-epochs* (in the experiments below, you'll not want to print after each single epoch), \n",
    "    you need to print out: \n",
    "    - The MBE on the training set and validation set (regardless of `max_patience`).\n",
    "    - The value of `patience` (if `max_patience` is not None).\n",
    "    E.g., `Epoch ..., training err ..., val err ..., patience ...` (in this case, `max_patience` is not None).\n",
    "    \n",
    "    After the training, you need to print out the info of returned Ws:\n",
    "    - The corresponding epoch.\n",
    "    - The corresponding MBE on the training set and validation set.\n",
    "    E.g., `Info of returned Ws: epoch ..., train err ..., val err ...`.\n",
    "    '''\n",
    "    # Init Ws\n",
    "    K = len(np.unique(train_Y)) # Num classes\n",
    "    layer_sizes = [train_X.shape[1] - 1] + hid_layer_sizes + [K]\n",
    "    np.random.seed(0) # This will fix the randomization; so, you and me will have the same results\n",
    "    Ws = [np.random.randn(layer_sizes[l]+1, layer_sizes[l+1]) / np.sqrt(layer_sizes[l]+1) \n",
    "          for l in range(len(layer_sizes)-1)]\n",
    "    \n",
    "    # TODO\n",
    "    one_hot_Y = np.zeros((len(train_Y), K))\n",
    "    one_hot_Y[np.arange(len(train_Y)), train_Y.reshape(-1)] = 1\n",
    "    errs = []\n",
    "    errs_val = []\n",
    "    best_MBE = 100\n",
    "    patience = max_patience\n",
    "    N = len(train_X) # Num training examples\n",
    "    rnd_idxs = range(N) # Random indexes    \n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(max_epoch):\n",
    "        if(patience != None):\n",
    "            if(patience <= 0):\n",
    "                break\n",
    "        \n",
    "        np.random.shuffle(rnd_idxs)\n",
    "        for start_idx in range(0, N, mb_size):\n",
    "            # Get minibach\n",
    "            mb_X = train_X[rnd_idxs[start_idx:start_idx+mb_size]]\n",
    "            mb_Y = one_hot_Y[rnd_idxs[start_idx:start_idx+mb_size]]\n",
    "            \n",
    "            # Forward-prop\n",
    "            As = compute_nnet_outputs(Ws, mb_X, True)\n",
    "            \n",
    "            # Back-prop; on the way, compute each layer's gradient and update its W\n",
    "            delta = As[-1] - mb_Y\n",
    "            grad = np.dot(As[-2].T,delta)*(1.0/int(mb_X.shape[0]))\n",
    "            Ws[-1] -= learning_rate * (grad + 2*wd_level*Ws[-1]) \n",
    "            for i in range(2, len(Ws) + 1):\n",
    "                delta = delta.dot(Ws[-i + 1].T[:, 1:]) * As[-i][:, 1:] * (1 - As[-i][:, 1:])\n",
    "                grad = np.dot(As[-i - 1].T, delta)*(1.0/int(mb_X.shape[0]))\n",
    "                Ws[-i] -= learning_rate * (grad + 2*wd_level*Ws[-i])\n",
    "        \n",
    "        # Compute training info, save it, and print it\n",
    "        A = compute_nnet_outputs(Ws, train_X, False)\n",
    "        err = np.mean(np.argmax(A, axis=1) != train_Y.squeeze()) * 100\n",
    "        errs.append(err)\n",
    "        \n",
    "        A = compute_nnet_outputs(Ws, val_X, False)\n",
    "        err_val = np.mean(np.argmax(A, axis=1) != val_Y.squeeze()) * 100\n",
    "        errs_val.append(err_val)\n",
    "        \n",
    "        if(patience != None):\n",
    "            if(err_val < best_MBE):\n",
    "                patience = max_patience\n",
    "                best_MBE = err_val\n",
    "            else:\n",
    "                patience = patience - 1\n",
    "        \n",
    "        if(patience != None):\n",
    "            if(epoch % 100 == 0):\n",
    "                print 'Epoch %d, training err %.3f, val err %.3f, patience %.3f' %(epoch, err, err_val, patience)\n",
    "        else:\n",
    "            if(epoch % 100 == 0):\n",
    "                print 'Epoch %d, train err %.3f, val err %.3f' %(epoch, err, err_val)\n",
    "    if(patience != None):\n",
    "        print 'Info of returned Ws: epoch %.3f, train err %.3f, val err %.3f' %(np.argmin(errs_val), errs[np.argmin(errs_val)], errs_val[np.argmin(errs_val)])\n",
    "    else:\n",
    "        print 'Info of returned Ws: epoch %.0f, train err %.3f, val err %.3f' %(max_epoch - 1, errs[max_epoch-1], errs_val[max_epoch-1])\n",
    "    return Ws, errs, errs_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thí nghiệm 1: ảnh hưởng của weight decay**\n",
    "\n",
    "Để thấy được ảnh hưởng của weight decay tới quá trình học, ta sẽ huấn luyện Neural Net với các giá trị `wd_level` khác nhau: 0., 0.001, 0.005; ở đây, ta cố định `hid_layer_sizes=[50], mb_size=len(train_X), learning_rate=0.1, max_patience=None, max_epoch=8000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train err 34.972, val err 41.899\n",
      "Epoch 100, train err 21.208, val err 24.022\n",
      "Epoch 200, train err 19.944, val err 18.994\n",
      "Epoch 300, train err 19.522, val err 18.994\n",
      "Epoch 400, train err 19.803, val err 18.994\n",
      "Epoch 500, train err 19.522, val err 19.553\n",
      "Epoch 600, train err 19.382, val err 19.553\n",
      "Epoch 700, train err 19.382, val err 19.553\n",
      "Epoch 800, train err 19.382, val err 19.553\n",
      "Epoch 900, train err 19.382, val err 19.553\n",
      "Epoch 1000, train err 19.382, val err 19.553\n",
      "Epoch 1100, train err 19.242, val err 19.553\n",
      "Epoch 1200, train err 18.961, val err 19.553\n",
      "Epoch 1300, train err 18.820, val err 19.553\n",
      "Epoch 1400, train err 18.820, val err 19.553\n",
      "Epoch 1500, train err 18.820, val err 19.553\n",
      "Epoch 1600, train err 18.820, val err 19.553\n",
      "Epoch 1700, train err 18.961, val err 19.553\n",
      "Epoch 1800, train err 18.961, val err 19.553\n",
      "Epoch 1900, train err 18.961, val err 19.553\n",
      "Epoch 2000, train err 18.961, val err 19.553\n",
      "Epoch 2100, train err 18.961, val err 18.994\n",
      "Epoch 2200, train err 18.680, val err 18.994\n",
      "Epoch 2300, train err 18.258, val err 18.994\n",
      "Epoch 2400, train err 18.118, val err 18.436\n",
      "Epoch 2500, train err 18.118, val err 18.436\n",
      "Epoch 2600, train err 17.837, val err 17.877\n",
      "Epoch 2700, train err 17.697, val err 18.436\n",
      "Epoch 2800, train err 17.416, val err 18.994\n",
      "Epoch 2900, train err 17.135, val err 18.994\n",
      "Epoch 3000, train err 17.275, val err 18.994\n",
      "Epoch 3100, train err 17.275, val err 18.994\n",
      "Epoch 3200, train err 17.416, val err 17.877\n",
      "Epoch 3300, train err 17.697, val err 17.877\n",
      "Epoch 3400, train err 17.556, val err 18.436\n",
      "Epoch 3500, train err 17.416, val err 18.436\n",
      "Epoch 3600, train err 17.275, val err 18.436\n",
      "Epoch 3700, train err 17.135, val err 18.436\n",
      "Epoch 3800, train err 16.994, val err 17.877\n",
      "Epoch 3900, train err 16.713, val err 17.318\n",
      "Epoch 4000, train err 16.713, val err 17.318\n",
      "Epoch 4100, train err 16.713, val err 17.318\n",
      "Epoch 4200, train err 16.573, val err 17.318\n",
      "Epoch 4300, train err 16.433, val err 17.318\n",
      "Epoch 4400, train err 16.433, val err 17.318\n",
      "Epoch 4500, train err 16.573, val err 17.318\n",
      "Epoch 4600, train err 16.292, val err 17.877\n",
      "Epoch 4700, train err 16.292, val err 17.877\n",
      "Epoch 4800, train err 16.152, val err 17.877\n",
      "Epoch 4900, train err 16.152, val err 17.877\n",
      "Epoch 5000, train err 16.152, val err 17.877\n",
      "Epoch 5100, train err 16.011, val err 18.436\n",
      "Epoch 5200, train err 16.152, val err 18.994\n",
      "Epoch 5300, train err 16.011, val err 18.994\n",
      "Epoch 5400, train err 15.449, val err 18.994\n",
      "Epoch 5500, train err 15.449, val err 18.436\n",
      "Epoch 5600, train err 15.449, val err 18.436\n",
      "Epoch 5700, train err 15.169, val err 18.436\n",
      "Epoch 5800, train err 15.169, val err 18.436\n",
      "Epoch 5900, train err 15.169, val err 18.436\n",
      "Epoch 6000, train err 15.169, val err 18.436\n",
      "Epoch 6100, train err 15.309, val err 18.436\n",
      "Epoch 6200, train err 15.309, val err 18.436\n",
      "Epoch 6300, train err 15.309, val err 18.994\n",
      "Epoch 6400, train err 15.309, val err 18.994\n",
      "Epoch 6500, train err 15.590, val err 19.553\n",
      "Epoch 6600, train err 15.449, val err 19.553\n",
      "Epoch 6700, train err 15.449, val err 19.553\n",
      "Epoch 6800, train err 15.449, val err 19.553\n",
      "Epoch 6900, train err 15.449, val err 19.553\n",
      "Epoch 7000, train err 15.590, val err 19.553\n",
      "Epoch 7100, train err 15.730, val err 19.553\n",
      "Epoch 7200, train err 15.730, val err 19.553\n",
      "Epoch 7300, train err 15.730, val err 19.553\n",
      "Epoch 7400, train err 15.730, val err 19.553\n",
      "Epoch 7500, train err 15.871, val err 19.553\n",
      "Epoch 7600, train err 15.871, val err 19.553\n",
      "Epoch 7700, train err 15.871, val err 19.553\n",
      "Epoch 7800, train err 15.871, val err 19.553\n",
      "Epoch 7900, train err 15.730, val err 19.553\n",
      "Info of returned Ws: epoch 7999, train err 15.730, val err 19.553\n"
     ]
    }
   ],
   "source": [
    "Ws_0, train_errs_0, val_errs_0 = train_nnet(train_X, train_Y, val_X, val_Y, hid_layer_sizes=[50], \n",
    "                                            wd_level=0.0, mb_size=len(train_X), learning_rate=0.1, \n",
    "                                            max_patience=None, max_epoch=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả của mình: \n",
    "\n",
    "`Info of returned Ws: epoch 7999, train err 15.730, val err 19.553`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train err 34.972, val err 41.899\n",
      "Epoch 100, train err 20.927, val err 24.022\n",
      "Epoch 200, train err 20.084, val err 18.994\n",
      "Epoch 300, train err 19.522, val err 18.994\n",
      "Epoch 400, train err 19.803, val err 18.994\n",
      "Epoch 500, train err 19.663, val err 19.553\n",
      "Epoch 600, train err 19.522, val err 19.553\n",
      "Epoch 700, train err 19.382, val err 19.553\n",
      "Epoch 800, train err 19.382, val err 19.553\n",
      "Epoch 900, train err 19.382, val err 19.553\n",
      "Epoch 1000, train err 19.242, val err 19.553\n",
      "Epoch 1100, train err 19.242, val err 19.553\n",
      "Epoch 1200, train err 19.242, val err 19.553\n",
      "Epoch 1300, train err 19.242, val err 19.553\n",
      "Epoch 1400, train err 19.242, val err 19.553\n",
      "Epoch 1500, train err 19.242, val err 19.553\n",
      "Epoch 1600, train err 19.242, val err 19.553\n",
      "Epoch 1700, train err 19.242, val err 19.553\n",
      "Epoch 1800, train err 19.242, val err 19.553\n",
      "Epoch 1900, train err 19.101, val err 19.553\n",
      "Epoch 2000, train err 19.101, val err 19.553\n",
      "Epoch 2100, train err 19.242, val err 19.553\n",
      "Epoch 2200, train err 19.242, val err 19.553\n",
      "Epoch 2300, train err 19.382, val err 19.553\n",
      "Epoch 2400, train err 19.382, val err 19.553\n",
      "Epoch 2500, train err 19.242, val err 19.553\n",
      "Epoch 2600, train err 19.242, val err 19.553\n",
      "Epoch 2700, train err 19.242, val err 19.553\n",
      "Epoch 2800, train err 19.242, val err 19.553\n",
      "Epoch 2900, train err 19.242, val err 19.553\n",
      "Epoch 3000, train err 19.242, val err 19.553\n",
      "Epoch 3100, train err 19.242, val err 19.553\n",
      "Epoch 3200, train err 19.101, val err 19.553\n",
      "Epoch 3300, train err 19.101, val err 19.553\n",
      "Epoch 3400, train err 19.101, val err 18.994\n",
      "Epoch 3500, train err 19.101, val err 18.994\n",
      "Epoch 3600, train err 19.101, val err 18.994\n",
      "Epoch 3700, train err 18.680, val err 18.994\n",
      "Epoch 3800, train err 18.680, val err 18.436\n",
      "Epoch 3900, train err 18.680, val err 18.436\n",
      "Epoch 4000, train err 18.399, val err 18.994\n",
      "Epoch 4100, train err 18.539, val err 18.436\n",
      "Epoch 4200, train err 18.399, val err 18.436\n",
      "Epoch 4300, train err 18.399, val err 18.436\n",
      "Epoch 4400, train err 18.399, val err 18.436\n",
      "Epoch 4500, train err 18.258, val err 18.436\n",
      "Epoch 4600, train err 18.258, val err 18.436\n",
      "Epoch 4700, train err 18.258, val err 18.436\n",
      "Epoch 4800, train err 18.258, val err 18.436\n",
      "Epoch 4900, train err 18.399, val err 18.436\n",
      "Epoch 5000, train err 18.399, val err 18.436\n",
      "Epoch 5100, train err 18.399, val err 18.436\n",
      "Epoch 5200, train err 18.539, val err 18.436\n",
      "Epoch 5300, train err 18.258, val err 18.436\n",
      "Epoch 5400, train err 18.118, val err 18.436\n",
      "Epoch 5500, train err 18.118, val err 18.436\n",
      "Epoch 5600, train err 18.118, val err 18.436\n",
      "Epoch 5700, train err 17.978, val err 18.436\n",
      "Epoch 5800, train err 17.978, val err 18.436\n",
      "Epoch 5900, train err 18.118, val err 18.994\n",
      "Epoch 6000, train err 18.118, val err 18.994\n",
      "Epoch 6100, train err 18.118, val err 18.994\n",
      "Epoch 6200, train err 18.118, val err 18.994\n",
      "Epoch 6300, train err 18.118, val err 18.994\n",
      "Epoch 6400, train err 18.118, val err 18.994\n",
      "Epoch 6500, train err 18.118, val err 18.994\n",
      "Epoch 6600, train err 18.258, val err 18.436\n",
      "Epoch 6700, train err 18.118, val err 17.877\n",
      "Epoch 6800, train err 18.118, val err 17.877\n",
      "Epoch 6900, train err 18.258, val err 17.877\n",
      "Epoch 7000, train err 18.258, val err 17.877\n",
      "Epoch 7100, train err 18.258, val err 17.877\n",
      "Epoch 7200, train err 18.258, val err 17.877\n",
      "Epoch 7300, train err 18.118, val err 17.877\n",
      "Epoch 7400, train err 18.118, val err 17.877\n",
      "Epoch 7500, train err 17.837, val err 17.877\n",
      "Epoch 7600, train err 17.697, val err 17.877\n",
      "Epoch 7700, train err 17.556, val err 17.877\n",
      "Epoch 7800, train err 17.556, val err 17.877\n",
      "Epoch 7900, train err 17.697, val err 17.877\n",
      "Info of returned Ws: epoch 7999, train err 17.697, val err 17.877\n"
     ]
    }
   ],
   "source": [
    "Ws_1, train_errs_1, val_errs_1 = train_nnet(train_X, train_Y, val_X, val_Y, hid_layer_sizes=[50], \n",
    "                                            wd_level=0.001, mb_size=len(train_X), learning_rate=0.1, \n",
    "                                            max_patience=None, max_epoch=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả của mình: \n",
    "\n",
    "`Info of returned Ws: epoch 7999, train err 17.697, val err 17.877`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train err 34.972, val err 41.899\n",
      "Epoch 100, train err 21.067, val err 24.581\n",
      "Epoch 200, train err 20.225, val err 18.994\n",
      "Epoch 300, train err 19.663, val err 19.553\n",
      "Epoch 400, train err 19.382, val err 20.112\n",
      "Epoch 500, train err 19.101, val err 20.112\n",
      "Epoch 600, train err 18.961, val err 18.994\n",
      "Epoch 700, train err 19.382, val err 19.553\n",
      "Epoch 800, train err 19.522, val err 19.553\n",
      "Epoch 900, train err 19.382, val err 19.553\n",
      "Epoch 1000, train err 19.382, val err 19.553\n",
      "Epoch 1100, train err 19.242, val err 19.553\n",
      "Epoch 1200, train err 19.242, val err 19.553\n",
      "Epoch 1300, train err 19.242, val err 19.553\n",
      "Epoch 1400, train err 19.242, val err 19.553\n",
      "Epoch 1500, train err 19.242, val err 19.553\n",
      "Epoch 1600, train err 19.101, val err 19.553\n",
      "Epoch 1700, train err 19.101, val err 19.553\n",
      "Epoch 1800, train err 19.242, val err 19.553\n",
      "Epoch 1900, train err 19.242, val err 19.553\n",
      "Epoch 2000, train err 19.242, val err 19.553\n",
      "Epoch 2100, train err 19.242, val err 19.553\n",
      "Epoch 2200, train err 19.242, val err 19.553\n",
      "Epoch 2300, train err 19.242, val err 19.553\n",
      "Epoch 2400, train err 19.242, val err 19.553\n",
      "Epoch 2500, train err 19.242, val err 19.553\n",
      "Epoch 2600, train err 19.242, val err 19.553\n",
      "Epoch 2700, train err 19.242, val err 19.553\n",
      "Epoch 2800, train err 19.242, val err 19.553\n",
      "Epoch 2900, train err 19.242, val err 19.553\n",
      "Epoch 3000, train err 19.242, val err 19.553\n",
      "Epoch 3100, train err 19.242, val err 19.553\n",
      "Epoch 3200, train err 19.242, val err 19.553\n",
      "Epoch 3300, train err 19.242, val err 19.553\n",
      "Epoch 3400, train err 19.242, val err 19.553\n",
      "Epoch 3500, train err 19.242, val err 19.553\n",
      "Epoch 3600, train err 19.242, val err 19.553\n",
      "Epoch 3700, train err 19.242, val err 19.553\n",
      "Epoch 3800, train err 19.242, val err 19.553\n",
      "Epoch 3900, train err 19.242, val err 19.553\n",
      "Epoch 4000, train err 19.242, val err 19.553\n",
      "Epoch 4100, train err 19.242, val err 19.553\n",
      "Epoch 4200, train err 19.242, val err 19.553\n",
      "Epoch 4300, train err 19.242, val err 19.553\n",
      "Epoch 4400, train err 19.242, val err 19.553\n",
      "Epoch 4500, train err 19.242, val err 19.553\n",
      "Epoch 4600, train err 19.242, val err 19.553\n",
      "Epoch 4700, train err 19.242, val err 19.553\n",
      "Epoch 4800, train err 19.242, val err 19.553\n",
      "Epoch 4900, train err 19.242, val err 19.553\n",
      "Epoch 5000, train err 19.242, val err 19.553\n",
      "Epoch 5100, train err 19.242, val err 19.553\n",
      "Epoch 5200, train err 19.242, val err 19.553\n",
      "Epoch 5300, train err 19.242, val err 19.553\n",
      "Epoch 5400, train err 19.242, val err 19.553\n",
      "Epoch 5500, train err 19.242, val err 19.553\n",
      "Epoch 5600, train err 19.242, val err 19.553\n",
      "Epoch 5700, train err 19.242, val err 19.553\n",
      "Epoch 5800, train err 19.242, val err 19.553\n",
      "Epoch 5900, train err 19.242, val err 19.553\n",
      "Epoch 6000, train err 19.242, val err 19.553\n",
      "Epoch 6100, train err 19.242, val err 19.553\n",
      "Epoch 6200, train err 19.242, val err 19.553\n",
      "Epoch 6300, train err 19.242, val err 19.553\n",
      "Epoch 6400, train err 19.242, val err 19.553\n",
      "Epoch 6500, train err 19.242, val err 19.553\n",
      "Epoch 6600, train err 19.242, val err 19.553\n",
      "Epoch 6700, train err 19.242, val err 19.553\n",
      "Epoch 6800, train err 19.242, val err 19.553\n",
      "Epoch 6900, train err 19.242, val err 19.553\n",
      "Epoch 7000, train err 19.242, val err 19.553\n",
      "Epoch 7100, train err 19.242, val err 19.553\n",
      "Epoch 7200, train err 19.242, val err 19.553\n",
      "Epoch 7300, train err 19.242, val err 19.553\n"
     ]
    }
   ],
   "source": [
    "Ws_2, train_errs_2, val_errs_2 = train_nnet(train_X, train_Y, val_X, val_Y, hid_layer_sizes=[50], \n",
    "                                            wd_level=0.005, mb_size=len(train_X), learning_rate=0.1, \n",
    "                                            max_patience=None, max_epoch=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả của mình: \n",
    "\n",
    "`Info of returned Ws: epoch 7999, train err 19.242, val err 19.553`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "num_epochs = len(train_errs_0)\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(range(num_epochs), train_errs_0, 'r', label='wd_level 0.000, train err')\n",
    "plt.plot(range(num_epochs), val_errs_0, 'r--', label='wd_level 0.000, val err')\n",
    "plt.xlabel('num epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(range(num_epochs), train_errs_1, 'g', label='wd_level 0.001, train err')\n",
    "plt.plot(range(num_epochs), val_errs_1, 'g--', label='wd_level 0.001, val err')\n",
    "plt.xlabel('num epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(range(num_epochs), train_errs_2, 'b', label='wd_level 0.005, train err')\n",
    "plt.plot(range(num_epochs), val_errs_2, 'b--', label='wd_level 0.005, val err')\n",
    "plt.xlabel('num epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(range(num_epochs), train_errs_0, 'r', label='wd_level 0.000, train err')\n",
    "plt.plot(range(num_epochs), val_errs_0, 'r--', label='wd_level 0.000, val err')\n",
    "plt.plot(range(num_epochs), train_errs_1, 'g', label='wd_level 0.001, train err')\n",
    "plt.plot(range(num_epochs), val_errs_1, 'g--', label='wd_level 0.001, val err')\n",
    "plt.plot(range(num_epochs), train_errs_2, 'b', label='wd_level 0.005, train err')\n",
    "plt.plot(range(num_epochs), val_errs_2, 'b--', label='wd_level 0.005, val err')\n",
    "plt.xlabel('num epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mình có đính kèm kết quả chạy của mình trong file `weight_decay.png`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Bình luận về đồ thị kết quả*        \n",
    "**Với weight decay càng lớn thì độ smooth của W càng lớn và ngược lại.        \n",
    "ta thấy với weight decay nhỏ hơn thì độ lỗi trong tập huấn luyện và tập thử validation càng bé.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thí nghiệm 2: ảnh hưởng của early stopping**\n",
    "\n",
    "Để thấy được ảnh hưởng của early stopping tới quá trình học, ta sẽ huấn luyện Neural Net với `max_patience=5000`; ở đây, ta cố định `hid_layer_sizes=[50], wd_level=0.0, mb_size=len(train_X), learning_rate=0.1, max_epoch=1000000(default)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ws_3, train_errs_3, val_errs_3 = train_nnet(train_X, train_Y, val_X, val_Y, hid_layer_sizes=[50], \n",
    "                                            wd_level=0.0, mb_size=len(train_X), learning_rate=0.1, \n",
    "                                            max_patience=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả của mình: \n",
    "\n",
    "`Info of returned Ws: epoch 3900, train err 16.713, val err 17.318`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "num_epochs = len(train_errs_3)\n",
    "stop_epoch = np.argmin(val_errs_3)\n",
    "plt.plot(range(num_epochs), train_errs_3, 'r', label='train err')\n",
    "plt.plot(range(num_epochs), val_errs_3, 'r--', label='val err')\n",
    "min_y, max_y = plt.ylim()\n",
    "plt.plot([stop_epoch, stop_epoch], [min_y, max_y])\n",
    "plt.xlabel('num epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend(loc='best')\n",
    "plt.text(stop_epoch, (min_y + max_y) / 2, 'STOP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mình có đính kèm kết quả chạy của mình trong file `early_stopping.png`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Bình luận về đồ thị kết quả*        \n",
    "**Với early stoppinng thì ta có thấy ngay tại vị trí mà khi Ein xuống không còn làm cho Eout xuống nữa thì lúc đó Ein không còn là người dẫn đường tốt cho Eout nên ta có thể cắt dừng tại vị trí đó.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm tra (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sẽ chọn `Ws` có độ lỗi nhỏ nhất trên tập validation làm bộ tham số của hàm dự đoán sau cùng; đó chính là `Ws_3` (dùng early stopping). Tất nhiên, ta có thể thí nghiệm thêm bằng cách kết hợp cả weight decay và early stopping (trong thực tế, người ta vẫn thường làm vậy, và có thể sẽ cho kết quả tốt hơn so với chỉ sử dụng weight decay hoặc early stopping). Mình đã có thí nghiệm nhưng độ lỗi trên tập validation không thấp hơn `Ws_3`; do đó, ta vẫn sẽ dùng `Ws_3` làm bộ tham số cuối cùng.\n",
    "\n",
    "Để đánh giá chất lượng của `Ws_3`, ta sẽ tiến hành dự đoán với các véc-tơ đầu vào của tập kiểm tra, rồi submit kết quả dự đoán lên Kaggle để biết được độ chính xác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Đọc dữ liệu tập kiểm tra vào data frame `test_input_df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_input_df = pd.read_csv('test.csv', index_col=0)\n",
    "test_input_df.info()\n",
    "test_input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Xây dựng `test_X` từ `test_input_df`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X = process_new_input_df(test_input_df, dropped_cols, mean_mode_dict, X_mean, X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Dự đoán nhãn lớp của test_X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds = np.argmax(compute_nnet_outputs(Ws_3, test_X, False), axis=1)\n",
    "\n",
    "# Create a data frame with `PassengerId` column (ids of passengers in test set) \n",
    "# and `Survived` column (predictions); then write it to a csv file\n",
    "preds_df = pd.DataFrame(preds, index=test_input_df.index, columns=['Survived'])\n",
    "preds_df.head()\n",
    "preds_df.to_csv('preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "*TODO: submit file `preds.csv` lên [Kaggle](https://www.kaggle.com/c/titanic/submissions/attach), và ghi nhận lại độ chính xác.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your submission scored 0.78469 your previous score of . Great job!              \n",
    "**Em đã thử với việc xử lý tên và thay đổi 1 tí về mô hình trong và có thể đạt được độ chính xác 0.79904**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
